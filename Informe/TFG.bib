@inproceedings{backEvolutionaryComputationOverview1996,
  title = {Evolutionary Computation: {{An}} Overview},
  shorttitle = {Evolutionary Computation},
  booktitle = {Proceedings of {{IEEE International Conference}} on {{Evolutionary Computation}}},
  author = {Back, T. and Schwefel, H.-P.},
  year = {1996},
  month = may,
  pages = {20--29},
  doi = {10.1109/ICEC.1996.542329},
  abstract = {We present an overview of the most important representatives of algorithms gleaned from natural evolution, so-called evolutionary algorithms. Evolution strategies, evolutionary programming, and genetic algorithms are summarized, with special emphasis on the principle of strategy parameter self-adaptation utilized by the first two algorithms to learn their own strategy parameters such as mutation variances and covariances. Some experimental results are presented which demonstrate the working principle and robustness of the self-adaptation methods used in evolution strategies and evolutionary programming. General principles of evolutionary algorithms are discussed, and we identify certain properties of natural evolution which might help to improve the problem solving capabilities of evolutionary algorithms even further.},
  keywords = {Algorithm design and analysis,Europe,Evolution (biology),Evolutionary computation,Genetic algorithms,Genetic mutations,Genetic programming,Optimization methods,Problem-solving,Robustness},
  note = {105 citations (Crossref) [2023-05-31]}
}

@book{banzhafGeneticProgrammingIntroduction1998,
  title = {Genetic Programming: An Introduction on the Automatic Evolution of Computer Programs and Its Applications},
  shorttitle = {Genetic Programming},
  editor = {Banzhaf, Wolfgang},
  year = {1998},
  publisher = {{Morgan Kaufmann Publishers ; Dpunkt-verlag}},
  address = {{San Francisco, Calif. : Heidelburg}},
  isbn = {978-1-55860-510-7 978-3-920993-58-4},
  langid = {english},
  lccn = {QA76.623 .G46 1998},
  keywords = {Genetic programming (Computer science)},
  file = {C\:\\Users\\irene\\Zotero\\storage\\ZESAUKXS\\Banzhaf - 1998 - Genetic programming an introduction on the automa.pdf}
}

@article{buiMetaheuristicAlgorithmsOptimizing2019,
  title = {Metaheuristic Algorithms in Optimizing Neural Network: A Comparative Study for Forest Fire Susceptibility Mapping in {{Dak Nong}}, {{Vietnam}}},
  shorttitle = {Metaheuristic Algorithms in Optimizing Neural Network},
  author = {Bui, Quang-Thanh},
  year = {2019},
  month = jan,
  journal = {Geomatics, Natural Hazards and Risk},
  volume = {10},
  number = {1},
  pages = {136--150},
  issn = {1947-5705, 1947-5713},
  doi = {10.1080/19475705.2018.1509902},
  urldate = {2023-05-18},
  abstract = {Meta-heuristic algorithms become common approaches in finding sufficiently good solutions for optimization problems. This study proposed and compared three novel hybrid methods, namely Biogeography-based Optimization (BBO), Gravitational Search Algorithm (GSA) and Grey Wolf Optimization (GWO) in combination with the popular Neural Network classifier for forest fire modeling. Dak Nong province was selected as a case study as it had undergone a critical drought season. One thousand three hundred and thirty-eight historic fired locations during the first several months of 2017 were chosen as dependent variables. On the other hand, topological, climatic and socio-economic data were used as independent predictor variables. For accuracy assessment, root mean square error derivable from the neural network was used as an objective function to be optimized by three proposed algorithms. The results showed that the area under Receiver Operating Characteristic curves (AUC) were in BBO (0.9515), GWO (0.9509), (0.9398) outperformed the Regular neural with backpropagation algorithm (AUC = 0.9271). Even though the differences between prediction results were small, but they were significant by using a paired t-test. It could be concluded that three hybrid models are suitable to map forest fire susceptibility in the selected study area and could be considered as alternative methods for studying forest fire in other locations.},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\KQCIZW7W\\Bui - 2019 - Metaheuristic algorithms in optimizing neural netw.pdf}
}

@inproceedings{chaturvediModifiedGeneticAlgorithm2019,
  title = {A {{Modified Genetic Algorithm Based}} on {{Improved Crossover Array Approach}}},
  booktitle = {Advances in {{Data}} and {{Information Sciences}}},
  author = {Chaturvedi, Stuti and Sharma, Vishnu P.},
  editor = {Kolhe, Mohan L. and Trivedi, Munesh C. and Tiwari, Shailesh and Singh, Vikash Kumar},
  year = {2019},
  series = {Lecture {{Notes}} in {{Networks}} and {{Systems}}},
  pages = {117--127},
  publisher = {{Springer}},
  address = {{Singapore}},
  doi = {10.1007/978-981-13-0277-0_10},
  abstract = {From several years, genetic algorithms are being used for solving many types of constrained and unconstrained optimization problems. Type of crossover operator, rate of crossover, replacement scheme and mutation rate are some of the essential factors that contribute to the efficiency of GA. Evidently, not one algorithm is suited for every problem according to the free lunch theorem but one form of crossover can solve a large number of problems. So many variants of GA are proposed in the past years with different types of crossover operators. So in this paper, we are introducing a new modified GA with improved crossover by dynamically choosing the type of crossover operator which is going to be used for the problem. Randomized mutation is used and a new virtual population is created which contains the best population so far. The modified GA is tested on 40 benchmark functions and the results are compared with the basic GA and one other GA variant.},
  isbn = {9789811302770},
  langid = {english},
  keywords = {Crossover array,Evolutionary algorithms,GA},
  file = {C\:\\Users\\irene\\Zotero\\storage\\624EYK8G\\Chaturvedi y Sharma - 2019 - A Modified Genetic Algorithm Based on Improved Cro.pdf}
}

@article{chengCrossoverIntensiveSearch1994,
  title = {Crossover on Intensive Search and Traveling Salesman Problem},
  author = {Cheng, Runwei and Gen, Mitsuo},
  year = {1994},
  month = sep,
  journal = {Computers \& Industrial Engineering},
  series = {16th {{Annual Conference}} on {{Computers}} and {{Industrial Engineering}}},
  volume = {27},
  number = {1},
  pages = {485--488},
  issn = {0360-8352},
  doi = {10.1016/0360-8352(94)90340-9},
  urldate = {2023-06-04},
  abstract = {This paper describes a new crossover operator for the traveling salesman problem, the greedy selection crossover operator (GSX for short), which is designed for path representation and performed at gene level. It can utilize both of local precedence and global precedence relationship among genes to perform intensive search among solution space to reproduce an improved offspring. It has been compared with other well known crossover operators and the results show that GSX operator is clearly superior to traditional operators. The proposed algorithm can be readily applied to other combinatorial optimization problems if a measure is properly defined based on the global information for a given problem.},
  langid = {english},
  keywords = {crossover,Genetic algorithm,traveling salesman problem},
  file = {C\:\\Users\\irene\\Zotero\\storage\\F2AFVEXZ\\0360835294903409.html}
}

@article{chughSurveyHandlingComputationally2019,
  title = {A Survey on Handling Computationally Expensive Multiobjective Optimization Problems with Evolutionary Algorithms},
  author = {Chugh, Tinkle and Sindhya, Karthik and Hakanen, Jussi and Miettinen, Kaisa},
  year = {2019},
  month = may,
  journal = {Soft Computing},
  volume = {23},
  doi = {10.1007/s00500-017-2965-0},
  abstract = {Evolutionary algorithms are widely used for solving multiobjective optimization problems but are often criticized because of a large number of function evaluations needed. Approximations, especially function approximations, also referred to as surrogates or metamodels are commonly used in the literature to reduce the computation time. This paper presents a survey of 45 different recent algorithms proposed in the literature between 2008 and 2016 to handle computationally expensive multiobjective optimization problems. Several algorithms are discussed based on what kind of an approximation such as problem, function or fitness approximation they use. Most emphasis is given to function approximation-based algorithms. We also compare these algorithms based on different criteria such as metamodeling technique and evolutionary algorithm used, type and dimensions of the problem solved, handling constraints, training time and the type of evolution control. Furthermore, we identify and discuss some promising elements and major issues among algorithms in the literature related to using an approximation and numerical settings used. In addition, we discuss selecting an algorithm to solve a given computationally expensive multiobjective optimization problem based on the dimensions in both objective and decision spaces and the computation budget available.},
  file = {C\:\\Users\\irene\\Zotero\\storage\\8GWHM2J2\\Chugh et al. - 2019 - A survey on handling computationally expensive mul.pdf}
}

@article{colakNEURALNETWORKSBASED,
  title = {{{NEURAL NETWORKS BASED META-HEURISTICS FOR SOLVING OPTIMIZATION PROBLEMS}}},
  author = {Colak, Selcuk},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\2PX6G8J5\\Colak - NEURAL NETWORKS BASED META-HEURISTICS FOR SOLVING .pdf}
}

@article{demoraesDiversityPreservationMethod2022,
  title = {A Diversity Preservation Method for Expensive Multi-Objective Combinatorial Optimization Problems Using {{Novel-First Tabu Search}} and {{MOEA}}/{{D}}},
  author = {{de Moraes}, Matheus Bernardelli and Coelho, Guilherme Palermo},
  year = {2022},
  month = sep,
  journal = {Expert Systems with Applications},
  volume = {202},
  pages = {117251},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2022.117251},
  urldate = {2023-06-02},
  abstract = {Expensive multi-objective combinatorial optimization problems have constraints in the number of objective function evaluations due to time, financial, or resource restrictions. As most combinatorial problems, they are subject to a high number of duplicated solutions. Given the fact that expensive environments limit the number of objective function evaluations, the existence of duplicated solutions heavily impacts the optimization process due to poor diversity and low convergence speed. This paper proposes the Novel-First Tabu Search, a greedy-strategy mechanism that uses Knowledge-Assisted Local Search methods to preserve the population diversity and increase the exploration and exploitation ability of MOEA/D. Experiments are conducted on constrained, unconstrained, multimodal, deceptive, linear, convex, and non-convex Pareto Front multi-objective combinatorial optimization benchmark problems. This paper also conducts an experiment on the real-world, expensive problem of Well Placement Optimization using a benchmark case based on the Namorado oil field, located in the Campos Basin, Brazil. The experimental results and performance comparison with state-of-the-art algorithms demonstrate that the proposed design significantly preserves diversity and increases convergence without violating the constraint in the number of objective function evaluations.},
  langid = {english},
  keywords = {Black-box optimization,Decomposition-based methods,Diversity preservation,Expensive multi-objective combinatorial optimization,Novel-First Tabu Search},
  file = {C\:\\Users\\irene\\Zotero\\storage\\I6LKVEW9\\de Moraes y Coelho - 2022 - A diversity preservation method for expensive mult.pdf;C\:\\Users\\irene\\Zotero\\storage\\VXNU4ZQG\\S0957417422006261.html}
}

@article{derracPracticalTutorialUse2011,
  title = {A Practical Tutorial on the Use of Nonparametric Statistical Tests as a Methodology for Comparing Evolutionary and Swarm Intelligence Algorithms},
  author = {Derrac, Joaqu{\'i}n and Garc{\'i}a, Salvador and Molina, Daniel and Herrera, Francisco},
  year = {2011},
  month = mar,
  journal = {Swarm and Evolutionary Computation},
  volume = {1},
  number = {1},
  pages = {3--18},
  issn = {22106502},
  doi = {10.1016/j.swevo.2011.02.002},
  urldate = {2023-05-20},
  abstract = {The interest in nonparametric statistical analysis has grown recently in the field of computational intelligence. In many experimental studies, the lack of the required properties for a proper application of parametric procedures \textendash{} independence, normality, and homoscedasticity \textendash{} yields to nonparametric ones the task of performing a rigorous comparison among algorithms.},
  langid = {english},
  note = {Test Estadisticos No param\'etricos
\par
Mirar la secci\'on 3 y 4 para rellenar el cap\'itulo de Contexto Matem\'atico respecto a los test estad\'isticos no param\'etricos},
  file = {C\:\\Users\\irene\\Zotero\\storage\\R3QTVWLN\\Derrac et al. - 2011 - A practical tutorial on the use of nonparametric s.pdf}
}

@article{eibenParameterControlEvolutionary1999,
  title = {Parameter Control in Evolutionary Algorithms},
  author = {Eiben, A.E. and Hinterding, R. and Michalewicz, Z.},
  year = {1999},
  month = jul,
  journal = {IEEE Transactions on Evolutionary Computation},
  volume = {3},
  number = {2},
  pages = {124--141},
  issn = {1941-0026},
  doi = {10.1109/4235.771166},
  abstract = {The issue of controlling values of various parameters of an evolutionary algorithm is one of the most important and promising areas of research in evolutionary computation: it has a potential of adjusting the algorithm to the problem while solving the problem. In the paper we: 1) revise the terminology, which is unclear and confusing, thereby providing a classification of such control mechanisms, and 2) survey various forms of control which have been studied by the evolutionary computation community in recent years. Our classification covers the major forms of parameter control in evolutionary computation and suggests some directions for further research.},
  keywords = {Bridges,Computer science,Evolutionary computation,Genetic mutations,Information technology,Power control,Problem-solving,Real time systems,Terminology},
  file = {C\:\\Users\\irene\\Zotero\\storage\\5EACUB69\\Eiben et al. - 1999 - Parameter control in evolutionary algorithms.pdf;C\:\\Users\\irene\\Zotero\\storage\\2FUU3THK\\771166.html}
}

@article{ekExplorationExploitationEvolutionary,
  title = {Exploration and {{Exploitation}} in {{Evolutionary Algorithms}}: {{A Survey}}},
  author = {Ek, Matej C{\textasciicaron} Repins{\textasciicaron} and Liu, Shih-Hsi and Mernik, Marjan},
  journal = {ACM Computing Surveys},
  volume = {1},
  number = {1},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\SQLIPEWT\\Ek et al. - Exploration and Exploitation in Evolutionary Algor.pdf}
}

@incollection{eshelmanCHCAdaptiveSearch1991a,
  title = {The {{CHC Adaptive Search Algorithm}}: {{How}} to {{Have Safe Search When Engaging}} in {{Nontraditional Genetic Recombination}}},
  shorttitle = {The {{CHC Adaptive Search Algorithm}}},
  booktitle = {Foundations of {{Genetic Algorithms}}},
  author = {Eshelman, Larry J.},
  year = {1991},
  volume = {1},
  pages = {265--283},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-08-050684-5.50020-3},
  urldate = {2023-06-03},
  abstract = {This paper describes and analyzes CHC, a nontraditional genetic algorithm which combines a conservative selection strategy that always preserves the best individuals found so far with a radical (highly disruptive) recombination operator that produces offspring that are maximally different from both parents. The traditional reasons for preferring a recombination operator with a low probability of disrupting schemata may not hold when such a conservative selection strategy is used. On the contrary, certain highly disruptive crossover operators provide more effective search. Empirical evidence is provided to support these claims.},
  isbn = {978-0-08-050684-5},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\4VKMBFQM\\Eshelman - 1991 - The CHC Adaptive Search Algorithm How to Have Saf.pdf}
}

@article{fernandesStudyNonrandomMating2001,
  title = {A {{Study}} on {{Non-random Mating}} and {{Varying Population Size}} in {{Genetic Algorithms Using}} a {{Royal Road Function}}},
  author = {Fernandes, Carlos and Rosa, Agostinho and Pais, Av and Norte, Torre},
  year = {2001},
  month = apr,
  abstract = {In this paper we present a study on the effects of non-random mating and varying population size in Genetic Algorithms (GAs) performance. We tested two algorithms: the non-incest Genetic Algorithm with varying population size (niGAVaPS) and the negative Assortative Mating Genetic Algorithm with varying population size (nAMGAVaPS), on a Royal Road function. These algorithms mimic natural species behavior by selecting parents according to parenthood (niGAVaPS) or phenotype similarity (nAMGAVaPS). We show that both algorithms outperform simple GA in the example shown. The results suggest that this may be due to the fact that genetic diversity is kept at a higher level by niGAVaPS and nAMGAVaPS, preventing the premature convergence of the algorithms to local optima. 1 Introduction The parent selection techniques used in the Simple Genetic Algorithm (simple GA) [Holland75] [Goldberg89] only take into account the individual fitness, that is, its adaptation to the problem (environment). In ...},
  file = {C\:\\Users\\irene\\Zotero\\storage\\H78UVKKP\\Fernandes et al. - 2001 - A Study on Non-random Mating and Varying Populatio.pdf}
}

@article{ferreiraFormulationsValidInequalities1996,
  title = {Formulations and Valid Inequalities for the Node Capacitated Graph Partitioning Problem},
  author = {Ferreira, C. E. and Martin, A. and {de Souza}, C. C. and Weismantel, R. and Wolsey, L. A.},
  year = {1996},
  month = sep,
  journal = {Mathematical Programming},
  volume = {74},
  number = {3},
  pages = {247--266},
  issn = {1436-4646},
  doi = {10.1007/BF02592198},
  urldate = {2023-06-04},
  abstract = {We investigate the problem of partitioning the nodes of a graph under capacity restriction on the sum of the node weights in each subset of the partition. The objective is to minimize the sum of the costs of the edges between the subsets of the partition. This problem has a variety of applications, for instance in the design of electronic circuits and devices. We present alternative integer programming formulations for this problem and discuss the links between these formulations. Having chosen to work in the space of edges of the multicut, we investigate the convex hull of incidence vectors of feasible multicuts. In particular, several classes of inequalities are introduced, and their strength and robustness are analyzed as various problem parameters change.},
  langid = {english},
  keywords = {Clustering,Ear decomposition,Equipartition,Graph partitioning,Integer programming,Knapsack},
  file = {C\:\\Users\\irene\\Zotero\\storage\\MSRXJVDP\\Ferreira et al. - 1996 - Formulations and valid inequalities for the node c.pdf}
}

@incollection{galloQuadraticKnapsackProblems1980,
  title = {Quadratic Knapsack Problems},
  booktitle = {Combinatorial {{Optimization}}},
  author = {Gallo, G. and Hammer, P. L. and Simeone, B.},
  editor = {Padberg, M. W.},
  year = {1980},
  series = {Mathematical {{Programming Studies}}},
  pages = {132--149},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/BFb0120892},
  urldate = {2023-06-04},
  abstract = {The quadratic knapsack (QK) model naturally arises in a variety of problems in operations research, statistics and combinatorics. Some ``upper planes'' for the QK problem are derived, and their different uses in a branch-and-bound scheme for solving such a problem are discussed. Some theoretical results concerning the class of all upper planes, as well as extensive computational experience, are reported.},
  isbn = {978-3-642-00802-3},
  langid = {english},
  keywords = {Branch-and-Bound,Computation,Knapsack Problem,Quadratic Programming,Upper Planes},
  file = {C\:\\Users\\irene\\Zotero\\storage\\EKQS79JC\\Gallo et al. - 1980 - Quadratic knapsack problems.pdf}
}

@article{garcia-martinezStrategicOscillationQuadratic2014,
  title = {Strategic Oscillation for the Quadratic Multiple Knapsack Problem},
  author = {{Garc{\'i}a-Mart{\'i}nez}, Carlos and Glover, Fred and Rodriguez, Francisco J. and Lozano, Manuel and Mart{\'i}, Rafael},
  year = {2014},
  month = may,
  journal = {Computational Optimization and Applications},
  volume = {58},
  number = {1},
  pages = {161--185},
  issn = {0926-6003, 1573-2894},
  doi = {10.1007/s10589-013-9623-y},
  urldate = {2022-10-26},
  abstract = {The quadratic multiple knapsack problem (QMKP) consists in assigning a set of objects, which interact through paired profit values, exclusively to different capacity-constrained knapsacks with the aim of maximising total profit. Its many applications include the assignment of workmen to different tasks when their ability to cooperate may affect the results.},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\MQAWZ92B\\García-Martínez et al. - 2014 - Strategic oscillation for the quadratic multiple k.pdf}
}

@article{garzonTECNICASAVANZADAS,
  title = {{TE\textasciiacute CNICAS AVANZADAS DE HIBRIDACIO\textasciiacute{} N PARA METAHEUR\textasciiacute ISTICAS}},
  author = {Garzon, Andrea Morales and Cabrera, Daniel Molina},
  abstract = {In this project we will study the behavior of hybrid models which are composed of different combinations of evolutionary algorithms, mainly, basic genetic algorithms. For this study we will use different real-coding problems obtained from CEC'14 (Test Function Suite Optimization). We will analyze the behavior of these algorithms for some of the functions of different characteristics: unimodal and multimodal functions, hybrid function, and other type of functions as result of a composition of previous functions working together.},
  langid = {spanish},
  file = {C\:\\Users\\irene\\Zotero\\storage\\BEG9NPWY\\Garzon y Cabrera - TE´CNICAS AVANZADAS DE HIBRIDACIO´ N PARA METAHEUR.pdf}
}

@article{gershmanDeconstructingHumanAlgorithms2018,
  title = {Deconstructing the Human Algorithms for Exploration},
  author = {Gershman, Samuel J.},
  year = {2018},
  month = apr,
  journal = {Cognition},
  volume = {173},
  pages = {34--42},
  issn = {00100277},
  doi = {10.1016/j.cognition.2017.12.014},
  urldate = {2023-03-12},
  abstract = {The dilemma between information gathering (exploration) and reward seeking (exploitation) is a fundamental problem for reinforcement learning agents. How humans resolve this dilemma is still an open question, because experiments have provided equivocal evidence about the underlying algorithms used by humans. We show that two families of algorithms can be distinguished in terms of how uncertainty affects exploration. Algorithms based on uncertainty bonuses predict a change in response bias as a function of uncertainty, whereas algorithms based on sampling predict a change in response slope. Two experiments provide evidence for both bias and slope changes, and computational modeling confirms that a hybrid model is the best quantitative account of the data.},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\W6E56GWP\\Gershman - 2018 - Deconstructing the human algorithms for exploratio.pdf}
}

@inproceedings{goldbergComparativeAnalysisSelection1991,
  title = {A {{Comparative Analysis}} of {{Selection Schemes Used}} in {{Genetic Algorithms}}},
  booktitle = {Foundations of {{Genetic Algorithms}}},
  author = {Goldberg, David E. and Deb, Kalyanmoy},
  year = {1991},
  volume = {1},
  pages = {69--93},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-08-050684-5.50008-2},
  urldate = {2023-06-17},
  abstract = {Semantic Scholar extracted view of "A Comparative Analysis of Selection Schemes Used in Genetic Algorithms" by D. Goldberg et al.},
  isbn = {978-0-08-050684-5},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\NDPJLVME\\Goldberg y Deb - 1991 - A Comparative Analysis of Selection Schemes Used i.pdf}
}

@article{grefenstetteOptimizationControlParameters1986,
  title = {Optimization of {{Control Parameters}} for {{Genetic Algorithms}}},
  author = {Grefenstette, John J.},
  year = {1986},
  month = jan,
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  volume = {16},
  number = {1},
  pages = {122--128},
  issn = {2168-2909},
  doi = {10.1109/TSMC.1986.289288},
  abstract = {The task of optimizing a complex system presents at least two levels of problems for the system designer. First, a class of optimization algorithms must be chosen that is suitable for application to the system. Second, various parameters of the optimization algorithm need to be tuned for efficiency. A class of adaptive search procedures called genetic algorithms (GA) has been used to optimize a wide variety of complex systems. GA's are applied to the second level task of identifying efficient GA's for a set of numerical optimization problems. The results are validated on an image registration problem. GA's are shown to be effective for both levels of the systems optimization problem.},
  keywords = {Adaptive control,Adaptive systems,Algorithm design and analysis,Control theory,Design optimization,Genetic algorithms,Image registration,Process control,Programmable control,Response surface methodology},
  file = {C\:\\Users\\irene\\Zotero\\storage\\BMKPJM7I\\4075583.html}
}

@misc{herrera-poyatosGeneticMemeticAlgorithm2017,
  title = {Genetic and {{Memetic Algorithm}} with {{Diversity Equilibrium}} Based on {{Greedy Diversification}}},
  author = {{Herrera-Poyatos}, Andr{\'e}s and Herrera, Francisco},
  year = {2017},
  month = feb,
  number = {arXiv:1702.03594},
  eprint = {1702.03594},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-02-18},
  abstract = {The lack of diversity in a genetic algorithm's population may lead to a bad performance of the genetic operators since there is not an equilibrium between exploration and exploitation. In those cases, genetic algorithms present a fast and unsuitable convergence. In this paper we develop a novel hybrid genetic algorithm which attempts to obtain a balance between exploration and exploitation. It confronts the diversity problem using the named greedy diversification operator. Furthermore, the proposed algorithm applies a competition between parent and children so as to exploit the high quality visited solutions. These operators are complemented by a simple selection mechanism designed to preserve and take advantage of the population diversity.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,I.2.8},
  note = {\section{Anotaciones\\
(13/3/2023 1:24:59)}

\par
"Greedy diversification operator" (Herrera-Poyatos y Herrera, 2017, p. 6) La diversidad de la poblaci\'on es una hoja de doble filo. Por lo que, es deseable un operador de diversificaci\'on que solo introduzca diversidad si es necesario
\par
"Population diversity is a double-edged sword" (Herrera-Poyatos y Herrera, 2017, p. 6)
\par
"Therefore, it is desired a diversification operator that only introduces diversity if it is necessary." (Herrera-Poyatos y Herrera, 2017, p. 6)
\par
"The diversification operator should delete the population's repeated chromosomes" (Herrera-Poyatos y Herrera, 2017, p. 6)
\par
"the chromosomes that are left in the population should have a good objective value and be potentially good for the crossover operator" (Herrera-Poyatos y Herrera, 2017, p. 6)
\par
"The diversification operator ought also to have a low computational cost" (Herrera-Poyatos y Herrera, 2017, p. 6)
\par
"We propose using a greedy randomized algorithm" (Herrera-Poyatos y Herrera, 2017, p. 6) GRASP
\par
"Greedy randomized algorithms provide acceptable chromosomes from the objective value perspective that also contain high quality genetic material thanks to the greedy selection function. The randomized aspect of the algorithm supplies the diversity required in the generated solutions" (Herrera-Poyatos y Herrera, 2017, p. 6) Razonamiento del uso de GRASP
\par
"elements whose greedy value is less than (1 + {$\sigma$}) times the best element's value," (Herrera-Poyatos y Herrera, 2017, p. 6) \textquestiondown Qu\'e elementos elegir para el GRASP?
\par
"This model obtains better solutions because it controls the quality of the elements added to the list. It also keeps the diversity in the generated solutions" (Herrera-Poyatos y Herrera, 2017, p. 6)
\par
"we use {$\sigma$} = 0.1 although this parameter can be optimized in each application domain" (Herrera-Poyatos y Herrera, 2017, p. 7)
\par
"the first element of our proposal is a diversification operator which uses the greedy randomized algorithm to substitute those chromosomes that share similarity characteristics with other population solutions" (Herrera-Poyatos y Herrera, 2017, p. 7)
\par
"This procedure increase the diversity and also keeps the population quality" (Herrera-Poyatos y Herrera, 2017, p. 7)
\par
"greedy diversification operator is used instead of the mutation operator" (Herrera-Poyatos y Herrera, 2017, p. 8) El operador de diversificaci\'on Greedy (GRASP) se usa en vez del operador de mutaci\'on
\par
"There are also models which work under small populations" (Herrera-Poyatos y Herrera, 2017, p. 10) Hay modelos que trabajan con poblaciones peque\~nas -{$>$} pedir archivo
\par
"Micro-genetic algorithms for stationary and non-stationary function optimization" (Herrera-Poyatos y Herrera, 2017, p. 26) Cuando tratamos con un problemas con alta dimensionalidad, puede ser dif\'icil o costoso en t\'erminos de tiempo para todos los par\'ametros del modelo converger dentro de un margen de error dado. En particular, cuando el n\'umero de par\'ametros del modelo aumenta, tambi\'en lo hace el tama\~no de poblaci\'on requerida.

Un tama\~no de poblaci\'on grande implica grandes n\'umeros de evaluaci\'on-coste.\\
Una alternativa es el uso de micro algoritmos gen\'eticos, que evolucionan poblaciones muy peque\~nas queson muy eficientes localizando \'areas prometedoras del espacio de b\'usqueda. Obviamente, las poblaciones peque\~nas son incapaces de mantener la diversidad por muchas generaciones, pero la poblaci\'on puede ser reiniciada cada vez que la poblaci\'on se pierde, manteniendo solo la mejor soluci\'on obtenida.

Reiniciar la poblaci\'on muchas veces durante la ejecuci\'on del algoritmo gen\'etico tiene el beneficio a\~nadido de evitar la convergencia prematura debido a la presencia de un individuo con un buen valor, lo que posee el riesgo de prevenir m\'as exploraciones del espacio de b\'usqueda y haga converger al programa a un m\'inimo local.

Adem\'as, en tanto que no estamos tratando con poblaciones largos, la convergencia puede ser alcanzada m\'as r\'apidamente y con menos requisitos de memoria para almacenar la poblaci\'on
\par
Comment: 27 pages, 5 figures, 11 tables},
  file = {C\:\\Users\\irene\\Zotero\\storage\\D5DHGSGV\\Herrera-Poyatos y Herrera - 2017 - Genetic and Memetic Algorithm with Diversity Equil}
}

@article{iaccaOckhamRazorMemetic2012,
  title = {Ockham's {{Razor}} in Memetic Computing: {{Three}} Stage Optimal Memetic Exploration},
  shorttitle = {Ockham's {{Razor}} in Memetic Computing},
  author = {Iacca, Giovanni and Neri, Ferrante and Mininno, Ernesto and Ong, Yew-Soon and Lim, Meng-Hiot},
  year = {2012},
  month = apr,
  journal = {Information Sciences},
  volume = {188},
  pages = {17--43},
  issn = {00200255},
  doi = {10.1016/j.ins.2011.11.025},
  urldate = {2023-03-12},
  abstract = {Memetic computing is a subject in computer science which considers complex structures as the combination of simple agents, memes, whose evolutionary interactions lead to intelligent structures capable of problem-solving. This paper focuses on memetic computing optimization algorithms and proposes a counter-tendency approach for algorithmic design. Research in the field tends to go in the direction of improving existing algorithms by combining different methods or through the formulation of more complicated structures. Contrary to this trend, we instead focus on simplicity, proposing a structurally simple algorithm with emphasis on processing only one solution at a time. The proposed algorithm, namely three stage optimal memetic exploration, is composed of three memes; the first stochastic and with a long search radius, the second stochastic and with a moderate search radius and the third deterministic and with a short search radius. The bottom-up combination of the three operators by means of a natural trial and error logic, generates a robust and efficient optimizer, capable of competing with modern complex and computationally expensive algorithms. This is suggestive of the fact that complexity in algorithmic structures can be unnecessary, if not detrimental, and that simple bottom-up approaches are likely to be competitive is here invoked as an extension to memetic computing basing on the philosophical concept of Ockham's Razor. An extensive experimental setup on various test problems and one digital signal processing application is presented. Numerical results show that the proposed approach, despite its simplicity and low computational cost displays a very good performance on several problems, and is competitive with sophisticated algorithms representing the-state-of-the-art in computational intelligence optimization.},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\7UNTBKYT\\Iacca et al. - 2012 - Ockham’s Razor in memetic computing Three stage o.pdf}
}

@book{islamMATHEMATICALPROGRAMMING2020,
  title = {{{MATHEMATICAL PROGRAMMING}}},
  author = {Islam, S.},
  year = {2020},
  month = jan,
  volume = {1},
  pages = {700},
  abstract = {This book consists of the preliminaries of mathematical programming, convex sets, topics of linear programming, integer linear programming, transportation problem, assignment problem and the basic of optimization using calculus method. Every topic has been presented in a simple way. The book becomes easier to understand for the readers, because, we follow the method definition-example-theory-example-application in writing each section. Students get here some done examples, mostly collected from the question papers of different universities. Exercises are included for home work. By studying the book, readers will learn the applications as well as the basic understanding of mathematical programming.},
  isbn = {978-620-0-46432-3},
  file = {C\:\\Users\\irene\\Zotero\\storage\\LF4BD6K2\\Islam - 2020 - MATHEMATICAL PROGRAMMING.pdf}
}

@article{jinComprehensiveSurveyFitness2005,
  title = {A Comprehensive Survey of Fitness Approximation in Evolutionary Computation},
  author = {Jin, Y.},
  year = {2005},
  month = jan,
  journal = {Soft Computing},
  volume = {9},
  number = {1},
  pages = {3--12},
  issn = {1433-7479},
  doi = {10.1007/s00500-003-0328-5},
  urldate = {2023-06-04},
  abstract = {Evolutionary algorithms (EAs) have received increasing interests both in the academy and industry. One main difficulty in applying EAs to real-world applications is that EAs usually need a large number of fitness evaluations before a satisfying result can be obtained. However, fitness evaluations are not always straightforward in many real-world applications. Either an explicit fitness function does not exist, or the evaluation of the fitness is computationally very expensive. In both cases, it is necessary to estimate the fitness function by constructing an approximate model. In this paper, a comprehensive survey of the research on fitness approximation in evolutionary computation is presented. Main issues like approximation levels, approximate model management schemes, model construction techniques are reviewed. To conclude, open questions and interesting issues in the field are discussed.},
  langid = {english},
  keywords = {Evolutionary computation,Fitness approximation,Meta-model,Optimization},
  file = {C\:\\Users\\irene\\Zotero\\storage\\36P6HH5W\\Jin - 2005 - A comprehensive survey of fitness approximation in.pdf}
}

@book{johnhhollandAdaptationNaturalArtificial1975,
  title = {Adaptation in {{Natural}} and {{Artificial Systems}}: {{An Introductory Analysis}} with {{Applications}} to {{Biology}}, {{Control}}, and {{Artificial Intelligence}}},
  author = {{John H Holland}},
  year = {1975},
  publisher = {{The MIT Press}},
  isbn = {0-262-58111-6 978-0-262-58111-0},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\IFPKZBKL\\John H. Holland - Adaptation in Natural and Artificial Systems_ An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence-The MIT Press (1992).pdf}
}

@inproceedings{joyMicroGeneticAlgorithmEmbedded2021,
  title = {Micro-{{Genetic Algorithm Embedded Multi-Population Differential Evolution}} Based {{Neural Network}} for {{Short-Term Load Forecasting}}},
  booktitle = {2021 56th {{International Universities Power Engineering Conference}} ({{UPEC}})},
  author = {Joy, Colin Paul and Pillai, Gobind and Chen, Yingke and Mistry, Kamlesh},
  year = {2021},
  month = aug,
  pages = {1--4},
  publisher = {{IEEE}},
  address = {{Middlesbrough, United Kingdom}},
  doi = {10.1109/UPEC50034.2021.9548262},
  urldate = {2023-03-15},
  abstract = {The load of a power system usually presents a certain range of nonlinear fluctuation with time. Even then, the load characteristics still follow certain rules which can be exploited to optimise and improve the accuracy of computerbased Short-Term Load Forecasting (STLF) models. Therefore, this paper presents a mGA (micro\textendash Genetic Algorithm) embedded multi-population DE (Differential Evolution) to optimise an Artificial Neural Network (ANN) STLF model. Firstly, the mGA embedded multi-population DE is proposed, to improve and balance the global and local search. Then the proposed DE is applied to optimise the weights during the training of the ANN. The overall model's performance is evaluated using publicly available Panama electricity load dataset against four state-of-the-art machine learning algorithms. The evaluation results show that the proposed DE based NN STLF model has higher prediction accuracy compared to the other selected machine learning algorithms.},
  isbn = {978-1-66544-389-0},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\MT3VUCJM\\Joy et al. - 2021 - Micro-Genetic Algorithm Embedded Multi-Population .pdf}
}

@article{latorrePrescriptionMethodologicalGuidelines2021,
  title = {A Prescription of Methodological Guidelines for Comparing Bio-Inspired Optimization Algorithms},
  author = {LaTorre, Antonio and Molina, Daniel and Osaba, Eneko and Poyatos, Javier and Del Ser, Javier and Herrera, Francisco},
  year = {2021},
  month = dec,
  journal = {Swarm and Evolutionary Computation},
  volume = {67},
  pages = {100973},
  issn = {2210-6502},
  doi = {10.1016/j.swevo.2021.100973},
  urldate = {2023-05-31},
  abstract = {Bio-inspired optimization (including Evolutionary Computation and Swarm Intelligence) is a growing research topic with many competitive bio-inspired algorithms being proposed every year. In such an active area, preparing a successful proposal of a new bio-inspired algorithm is not an easy task. Given the maturity of this research field, proposing a new optimization technique with innovative elements is no longer enough. Apart from the novelty, results reported by the authors should be proven to achieve a significant advance over previous outcomes from the state of the art. Unfortunately, not all new proposals deal with this requirement properly. Some of them fail to select appropriate benchmarks or reference algorithms to compare with. In other cases, the validation process carried out is not defined in a principled way (or is even not done at all). Consequently, the significance of the results presented in such studies cannot be guaranteed. In this work we review several recommendations in the literature and propose methodological guidelines to prepare a successful proposal, taking all these issues into account. We expect these guidelines to be useful not only for authors, but also for reviewers and editors along their assessment of new contributions to the field.},
  langid = {english},
  keywords = {Benchmarking,Bio-inspired optimization,Comparison methodologies,Guidelines,Parameter tuning,Recommendations review,Statistical analysis},
  note = {43 citations (Crossref) [2023-05-31]},
  file = {C\:\\Users\\irene\\Zotero\\storage\\NCWKZRNF\\LaTorre et al. - 2021 - A prescription of methodological guidelines for co.pdf}
}

@article{liEvolutionaryComputationExpensive2022,
  title = {Evolutionary {{Computation}} for {{Expensive Optimization}}: {{A Survey}}},
  shorttitle = {Evolutionary {{Computation}} for {{Expensive Optimization}}},
  author = {Li, Jian-Yu and Zhan, Zhi-Hui and Zhang, Jun},
  year = {2022},
  month = feb,
  journal = {Machine Intelligence Research},
  volume = {19},
  number = {1},
  pages = {3--23},
  issn = {2731-538X, 2731-5398},
  doi = {10.1007/s11633-022-1317-4},
  urldate = {2022-10-05},
  abstract = {Expensive optimization problem (EOP) widely exists in various significant real-world applications. However, EOP requires expensive or even unaffordable costs for evaluating candidate solutions, which is expensive for the algorithm to find a satisfactory solution. Moreover, due to the fast-growing application demands in the economy and society, such as the emergence of the smart cities, the internet of things, and the big data era, solving EOP more efficiently has become increasingly essential in various fields, which poses great challenges on the problem-solving ability of optimization approach for EOP. Among various optimization approaches, evolutionary computation (EC) is a promising global optimization tool widely used for solving EOP efficiently in the past decades. Given the fruitful advancements of EC for EOP, it is essential to review these advancements in order to synthesize and give previous research experiences and references to aid the development of relevant research fields and real-world applications. Motivated by this, this paper aims to provide a comprehensive survey to show why and how EC can solve EOP efficiently. For this aim, this paper firstly analyzes the total optimization cost of EC in solving EOP. Then, based on the analysis, three promising research directions are pointed out for solving EOP, which are problem approximation and substitution, algorithm design and enhancement, and parallel and distributed computation. Note that, to the best of our knowledge, this paper is the first that outlines the possible directions for efficiently solving EOP by analyzing the total expensive cost. Based on this, existing works are reviewed comprehensively via a taxonomy with four parts, including the above three research directions and the real-world application part. Moreover, some future research directions are also discussed in this paper. It is believed that such a survey can attract attention, encourage discussions, and stimulate new EC research ideas for solving EOP and related real-world applications more efficiently.},
  langid = {english},
  note = {Definici\'on EOP
\par
\textquestiondown Ejemplos?},
  file = {C\:\\Users\\irene\\Zotero\\storage\\V2I6X9CN\\Li et al. - 2022 - Evolutionary Computation for Expensive Optimizatio.pdf}
}

@inproceedings{lisParallelGeneticAlgorithm1996,
  title = {Parallel Genetic Algorithm with the Dynamic Control Parameter},
  booktitle = {Proceedings of {{IEEE International Conference}} on {{Evolutionary Computation}}},
  author = {Lis, J.},
  year = {1996},
  month = may,
  pages = {324--329},
  doi = {10.1109/ICEC.1996.542383},
  abstract = {A parallel genetic algorithm with dynamic mutation probability is presented. This algorithm is based on the farming model of parallel computation. The basic idea of the dynamic establishing mutation rate is presented. Some experiments on function maximization problems have been performed to study the effects of varying the mutation rate for the parallel model.},
  keywords = {Biological cells,Convergence,Cost function,Electronics packaging,Genetic algorithms,Genetic mutations,Optimal control,Robustness,Stochastic processes,Testing},
  file = {C\:\\Users\\irene\\Zotero\\storage\\GSQ4FWHM\\542383.html}
}

@article{loboOverviewParameterlessGenetic2008,
  title = {An Overview of the Parameter-Less Genetic Algorithm},
  author = {Lobo, Fernando and Goldberg, David},
  year = {2008},
  month = jan,
  abstract = {This paper presents an overview of the parameter-less genetic algorithm and shows its application to a network expansion prob-lem. The technique simplifies genetic algo-rithm operation by incorporating knowledge of parameter selection and population sizing theory in the genetic algorithm itself.},
  file = {C\:\\Users\\irene\\Zotero\\storage\\GWDF5GB9\\Lobo y Goldberg - 2008 - An overview of the parameter-less genetic algorith.pdf}
}

@inproceedings{mahfoudCrowdingPreselectionRevisited1992,
  title = {Crowding and {{Preselection Revisited}}},
  booktitle = {Parallel {{Problem Solving}} from {{Nature}}},
  author = {Mahfoud, Samir W.},
  year = {1992},
  urldate = {2023-06-17},
  abstract = {This paper considers the related algorithms, crowding and preselection, as potential multimodal function optimizers. It examines the ability of the two algorithms to preserve diversity, especially multimodal diversity. Crowding is analyzed in terms of the number of replacement errors it makes. Diierent strategies for reducing or eliminating error are proposed and examined. Finally, a variation of preselection is presented which approximates crowding, virtually eliminates replacement error, and restores selection pressure.},
  note = {[TLDR] This paper considers the related algorithms, crowding and preselection, as potential multimodal function optimizers and examines the ability of the two algorithms to preserve diversity, especially multi-modal diversity.}
}

@article{martinezLightsShadowsEvolutionary2021b,
  title = {Lights and Shadows in {{Evolutionary Deep Learning}}: {{Taxonomy}}, Critical Methodological Analysis, Cases of Study, Learned Lessons, Recommendations and Challenges},
  shorttitle = {Lights and Shadows in {{Evolutionary Deep Learning}}},
  author = {Martinez, Aritz D. and Del Ser, Javier and {Villar-Rodriguez}, Esther and Osaba, Eneko and Poyatos, Javier and Tabik, Siham and Molina, Daniel and Herrera, Francisco},
  year = {2021},
  month = mar,
  journal = {Information Fusion},
  volume = {67},
  pages = {161--194},
  issn = {1566-2535},
  doi = {10.1016/j.inffus.2020.10.014},
  urldate = {2023-05-31},
  abstract = {Much has been said about the fusion of bio-inspired optimization algorithms and Deep Learning models for several purposes: from the discovery of network topologies and hyperparametric configurations with improved performance for a given task, to the optimization of the model's parameters as a replacement for gradient-based solvers. Indeed, the literature is rich in proposals showcasing the application of assorted nature-inspired approaches for these tasks. In this work we comprehensively review and critically examine contributions made so far based on three axes, each addressing a fundamental question in this research avenue: (a) optimization and taxonomy (Why?), including a historical perspective, definitions of optimization problems in Deep Learning, and a taxonomy associated with an in-depth analysis of the literature, (b) critical methodological analysis (How?), which together with two case studies, allows us to address learned lessons and recommendations for good practices following the analysis of the literature, and (c) challenges and new directions of research (What can be done, and what for?). In summary, three axes \textendash{} optimization and taxonomy, critical analysis, and challenges \textendash{} which outline a complete vision of a merger of two technologies drawing up an exciting future for this area of fusion research.},
  langid = {english},
  keywords = {Deep Learning,Evolutionary Computation,Neuroevolution,Swarm Intelligence},
  note = {12 citations (Crossref) [2023-05-31]
\par
Neuroevoluci\'on},
  file = {C\:\\Users\\irene\\Zotero\\storage\\JZ9Q3AJJ\\Martinez et al. - 2021 - Lights and shadows in Evolutionary Deep Learning .pdf}
}

@inproceedings{matsuiNewSelectionMethod1999a,
  title = {New Selection Method to Improve the Population Diversity in Genetic Algorithms},
  booktitle = {{{IEEE SMC}}'99 {{Conference Proceedings}}. 1999 {{IEEE International Conference}} on {{Systems}}, {{Man}}, and {{Cybernetics}} ({{Cat}}. {{No}}.{{99CH37028}})},
  author = {Matsui, K.},
  year = {1999},
  month = oct,
  volume = {1},
  pages = {625-630 vol.1},
  issn = {1062-922X},
  doi = {10.1109/ICSMC.1999.814164},
  abstract = {We present a new method of selection, in order to improve the population diversity in the genotype distribution, in genetic algorithms (GAs). The problem of maintaining of the population diversity is very important in designing genetic operators, when GAs are applied to optimization problems. Therefore, we propose two types of new selection operators based on the correlations between individuals' genotypes, for improving the population diversity. The first operator is a new type of selection for reproduction, namely the correlative tournament selection. The second operator is a new type of selection for survival, namely correlative family-based selection. We have applied our GA to two different problems: Royal road problems, and Knapsack problems with non-stationary environments. We have compared our method with the other representative GA model, and have shown the effectiveness of the proposed GA models.},
  keywords = {Biological system modeling,Biology computing,Computational modeling,Design optimization,Erbium,Genetic algorithms,Optimization methods,Process design,Stochastic processes,Testing},
  note = {14 citations (Crossref) [2023-05-31]}
}

@book{mcconnellCodeComplete2004,
  title = {Code Complete},
  author = {McConnell, Steve},
  year = {2004},
  edition = {2nd ed},
  publisher = {{Microsoft Press}},
  address = {{Redmond, Wash}},
  isbn = {978-0-7356-1967-8},
  langid = {english},
  lccn = {QA76.76.D47 M39 2004},
  keywords = {Computer software,Development,{Handbooks, manuals, etc}},
  file = {C\:\\Users\\irene\\Zotero\\storage\\8BKXVVLV\\McConnell - 2004 - Code complete.pdf}
}

@book{michalewiczHandbookEvolutionaryComputation1997,
  title = {Handbook of {{Evolutionary Computation}}},
  author = {Michalewicz, Z. and Baeck, Thomas and Fogel, D.B.},
  year = {1997},
  month = jan,
  publisher = {{CRC Press}},
  address = {{Boca Raton}},
  doi = {10.1201/9780367802486},
  abstract = {Many scientists and engineers now use the paradigms of evolutionary computation (genetic algorithms, evolution strategies, evolutionary programming, genetic programming, classifier systems, and combinations or hybrids) to tackle problems that are either intractable or unrealistically time consuming to solve through traditional computational strategies. The Handbook of Evolutionary Computation addresses the need for a comprehensive source of reference in the maturing field of evolutionary computation. The handbook is available in a looseleaf print format and an online format.},
  isbn = {978-0-367-80248-6},
  file = {C\:\\Users\\irene\\Zotero\\storage\\BUQU67PT\\Michalewicz, D. B. Fogel - 1997 - Handbook of Evolutionary Computation.pdf}
}

@article{oppacherShiftingBalanceGenetic,
  title = {The {{Shifting Balance Genetic Algorithm}}: {{Improving}} the {{GA}} in a {{Dynamic Environment}}},
  author = {Oppacher, Franz and Wineberg, Mark},
  abstract = {Two observed deficiencies of the GA are its tendency to get trapped at local maxima and the difficulty it has handling a changing environment after convergence has occurred. A mechanism proposed by Sewall Wright in the 1930s addresses the problem of premature convergence: his Shifting Balance Theory (SBT) of evolution. In this work the SBT has been modified to remove defects inherent in its original formulation, while keeping the properties that should both increase the adaptive abilities of the GA and prevent it from prematurely converging. The system has been implemented and is called the Shifting Balance Genetic Algorithm (SBGA). Experimental results and analysis are presented demonstrating that the SBGA does, in fact, lessen the problem of premature convergence and also improves performance under a dynamic environment, thereby mitigating both deficiencies.},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\YA44AL4J\\Oppacher y Wineberg - The Shifting Balance Genetic Algorithm Improving .pdf}
}

@inproceedings{pellerinSelfadaptiveParametersGenetic2004,
  title = {Self-Adaptive Parameters in Genetic Algorithms},
  booktitle = {Defense and {{Security}}},
  author = {Pellerin, Eric and Pigeon, Luc and Delisle, Sylvain},
  editor = {Dasarathy, Belur V.},
  year = {2004},
  month = apr,
  pages = {53},
  address = {{Orlando, FL}},
  doi = {10.1117/12.542156},
  urldate = {2023-06-04},
  abstract = {Genetic algorithms are powerful search algorithms that can be applied to a wide range of problems. Generally, parameter setting is accomplished prior to running a Genetic Algorithm (GA) and this setting remains unchanged during execution. The problem of interest to us here is the self-adaptive parameters adjustment of a GA. In this research, we propose an approach in which the control of a genetic algorithm's parameters can be encoded within the chromosome of each individual. The parameters' values are entirely dependent on the evolution mechanism and on the problem context. Our preliminary results show that a GA is able to learn and evaluate the quality of self-set parameters according to their degree of contribution to the resolution of the problem. These results are indicative of a promising approach to the development of GAs with self-adaptive parameter settings that do not require the user to pre-adjust parameters at the outset.},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\9JDBFBSR\\Pellerin et al. - 2004 - Self-adaptive parameters in genetic algorithms.pdf}
}

@book{phamCompetitiveEvolutionNatural1994,
  title = {Competitive {{Evolution}}: {{A Natural Approach}} to {{Operator Selection}}.},
  shorttitle = {Competitive {{Evolution}}},
  author = {Pham, Tuan},
  year = {1994},
  month = jan,
  volume = {956},
  pages = {60},
  doi = {10.1007/3-540-60154-6_47},
  abstract = {One of the main problems in applying evolutionary optimisation methods is the choice of operators and parameter values. This paper propose a competitive evolution method, in which several subpopulations are allowed to compete for computer time. The population with the fittest members, and that with the highest improvement rate in the recent past, are rewarded. When using identical strategies in the subpopulations, this competitive strategy provides an insurance against unlucky runs while extracting only an insignificant cost in terms of extra function evaluations. When using different strategies in the subpopulations, it ensures that the best strategies are used and again the extra cost is not great. Competitive evolution is at its best when an operator \textemdash{} or the lack of it \textemdash{} may have a very detrimental effect which is not known in advance. Occasional mixing of the best performing subpopulations leads to further improvement.},
  isbn = {978-3-540-60154-8},
  file = {C\:\\Users\\irene\\Zotero\\storage\\VDKN8S99\\Pham - 1994 - Competitive Evolution A Natural Approach to Opera.pdf}
}

@article{pisingerQuadraticKnapsackProblem2007,
  title = {The Quadratic Knapsack Problem\textemdash a Survey},
  author = {Pisinger, David},
  year = {2007},
  month = mar,
  journal = {Discrete Applied Mathematics},
  volume = {155},
  number = {5},
  pages = {623--648},
  issn = {0166218X},
  doi = {10.1016/j.dam.2006.08.007},
  urldate = {2022-10-26},
  abstract = {The binary quadratic knapsack problem maximizes a quadratic objective function subject to a linear capacity constraint. Due to its simple structure and challenging difficulty it has been studied intensively during the last two decades. The present paper gives a survey of upper bounds presented in the literature, and show the relative tightness of several of the bounds. Techniques for deriving the bounds include relaxation from upper planes, linearization, reformulation, Lagrangian relaxation, Lagrangian decomposition, and semidefinite programming. A short overview of heuristics, reduction techniques, branch-and-bound algorithms and approximation results is given, followed by an overview of valid inequalities for the quadratic knapsack polytope. The paper is concluded by an experimental study where the upper bounds presented are compared with respect to strength and computational effort.},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\RJ82WUKI\\Pisinger - 2007 - The quadratic knapsack problem—a survey.pdf}
}

@article{poyatosEvoPruneDeepTLEvolutionaryPruning2023a,
  title = {{{EvoPruneDeepTL}}: {{An}} Evolutionary Pruning Model for Transfer Learning Based Deep Neural Networks},
  shorttitle = {{{EvoPruneDeepTL}}},
  author = {Poyatos, Javier and Molina, Daniel and Martinez, Aritz D. and Del Ser, Javier and Herrera, Francisco},
  year = {2023},
  month = jan,
  journal = {Neural Networks},
  volume = {158},
  pages = {59--82},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2022.10.011},
  urldate = {2023-05-31},
  abstract = {In recent years, Deep Learning models have shown a great performance in complex optimization problems. They generally require large training datasets, which is a limitation in most practical cases. Transfer learning allows importing the first layers of a pre-trained architecture and connecting them to fully-connected layers to adapt them to a new problem. Consequently, the configuration of the these layers becomes crucial for the performance of the model. Unfortunately, the optimization of these models is usually a computationally demanding task. One strategy to optimize Deep Learning models is the pruning scheme. Pruning methods are focused on reducing the complexity of the network, assuming an expected performance penalty of the model once pruned. However, the pruning could potentially be used to improve the performance, using an optimization algorithm to identify and eventually remove unnecessary connections among neurons. This work proposes EvoPruneDeepTL, an evolutionary pruning model for Transfer Learning based Deep Neural Networks which replaces the last fully-connected layers with sparse layers optimized by a genetic algorithm. Depending on its solution encoding strategy, our proposed model can either perform optimized pruning or feature selection over the densely connected part of the neural network. We carry out different experiments with several datasets to assess the benefits of our proposal. Results show the contribution of EvoPruneDeepTL and feature selection to the overall computational efficiency of the network as a result of the optimization process. In particular, the accuracy is improved, reducing at the same time the number of active neurons in the final layers.},
  langid = {english},
  keywords = {Deep learning,Evolutionary algorithms,Feature selection,Pruning,Transfer learning},
  note = {1 citations (Crossref) [2023-05-31]
\par
Ejemplo concreto de redes neuronales en las que se vieron obligaron a bajar el n\'umero},
  file = {C\:\\Users\\irene\\Zotero\\storage\\WDC5ABGW\\Poyatos et al. - 2023 - EvoPruneDeepTL An evolutionary pruning model for .pdf}
}

@article{qiongbingNewCrossoverMechanism2016,
  title = {A New Crossover Mechanism for Genetic Algorithms with Variable-Length Chromosomes for Path Optimization Problems},
  author = {Qiongbing, Zhang and Lixin, Ding},
  year = {2016},
  month = oct,
  journal = {Expert Systems with Applications},
  volume = {60},
  pages = {183--189},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2016.04.005},
  urldate = {2023-06-04},
  abstract = {Genetic Algorithm (GA) has found wide application in path optimization problem. In many fields such as navigating system, oil transportation, paths between the starting node and the termination node often have distinct number of relay-nodes, which leads to the corresponding chromosomes would have different length. We refer to chromosomes with non-consistent lengths as the variable-length chromosomes. This paper first investigated GAs with variable-length chromosomes widely used and found that Same Point (SP) crossover is the most popular crossover mechanism. Then, a new crossover mechanism called Same Adjacency (SA) is proposed for GA with variable-length chromosomes for path optimization problem, which outperforms GA with SP by a better search capability as the mathematical analysis shows. The simulation study indicates that GAs with our crossover operators could obtain a better solution, as compared to GAs with SP, while still being able to converge fast in different networks with varied sizes.},
  langid = {english},
  keywords = {Crossover,Genetic algorithm,Path optimal,Variable-length chromosomes},
  file = {C\:\\Users\\irene\\Zotero\\storage\\NVZMF6S6\\S0957417416301634.html}
}

@misc{QuadraticMultipleKnapsack,
  title = {Quadratic {{Multiple Knapsack Problem}}},
  urldate = {2023-06-06},
  howpublished = {https://grafo.etsii.urjc.es/optsicom/qmkp.html\#state-of-the-art-methods},
  file = {C\:\\Users\\irene\\Zotero\\storage\\KDNM5PNG\\qmkp.html}
}

@article{reevesFeatureArticleGenetic1997,
  title = {Feature {{Article}}\textemdash{{Genetic Algorithms}} for the {{Operations Researcher}}},
  author = {Reeves, Colin R.},
  year = {1997},
  month = aug,
  journal = {INFORMS Journal on Computing},
  volume = {9},
  number = {3},
  pages = {231--250},
  publisher = {{INFORMS}},
  issn = {1091-9856},
  doi = {10.1287/ijoc.9.3.231},
  urldate = {2023-05-31},
  abstract = {Genetic algorithms have become increasingly popular as a means of solving hard combinatorial optimization problems of the type familiar in operations research. This feature article will consider what genetic algorithms have achieved in this area, discuss some of the factors that influence their success or failure, and offer a guide for operations researchers who want to get the best out of them.},
  keywords = {genetic algorithms,heuristics,optimization},
  file = {C\:\\Users\\irene\\Zotero\\storage\\3Y3MFBZH\\Reeves - 1997 - Feature Article—Genetic Algorithms for the Operati.pdf}
}

@incollection{reevesGeneticAlgorithms2010,
  title = {Genetic {{Algorithms}}},
  booktitle = {Handbook of {{Metaheuristics}}},
  author = {Reeves, Colin},
  year = {2010},
  month = sep,
  volume = {146},
  pages = {109--139},
  doi = {10.1007/978-1-4419-1665-5_5},
  abstract = {Genetic algorithms (GAs) have become popular as a means of solving hard combinatorial optimization problems. The first part of this chapter briefly traces their history, explains the basic concepts and discusses some of their theoretical aspects. It also references a number of sources for further research into their applications. The second part concentrates on the detailed implementation of a GA. It discusses the fundamentals of encoding a `genotype' in different circumstances and describes the mechanics of population selection and management and the choice of genetic `operators' for generating new populations. In closing, some specific guidelines for using GAs in practice are provided.},
  file = {C\:\\Users\\irene\\Zotero\\storage\\NJII4H5F\\Reeves - 2010 - Genetic Algorithms.pdf}
}

@article{rhysSelectionProblemShared1970,
  title = {A {{Selection Problem}} of {{Shared Fixed Costs}} and {{Network Flows}}},
  author = {Rhys, J. M. W.},
  year = {1970},
  month = nov,
  journal = {Management Science},
  volume = {17},
  number = {3},
  pages = {200--207},
  issn = {0025-1909, 1526-5501},
  doi = {10.1287/mnsc.17.3.200},
  urldate = {2023-06-04},
  abstract = {An apparently combinatorial problem is defined, and a method given for solution by reduction to a network flow problem. The basic problem defined is that of assessing the desirability of incurring a number of fixed costs, when the benefits to be obtained cannot be related to individual cost-incurring items (facilities) but only to combinations.},
  langid = {english}
}

@article{rodriguezALGORITMOSBIOINSPIRADOSCON,
  title = {{ALGORITMOS BIOINSPIRADOS CON INTERACCIONES NEGATIVAS}},
  author = {Rodr{\'i}guez, Carmen Biedma and Cabrera, Daniel Molina and Triguero, Francisco Herrera},
  abstract = {We know that all metaheuristics have a very important aspect to consider if we want good results, the diversity. There are a lot of techniques to provide this quality, but a few years ago appeared once called repulsion. With this component we will achieve that our set of solutions keep the diversity every moment, consequenquentially we will have better solutions and the avoidance of local minimums.},
  langid = {spanish},
  file = {C\:\\Users\\irene\\Zotero\\storage\\7HW4EBBY\\Rodríguez et al. - ALGORITMOS BIOINSPIRADOS CON INTERACCIONES NEGATIV.pdf}
}

@article{rojasMemeticMicrogeneticAlgorithms2023,
  title = {Memetic Micro-Genetic Algorithms for Cancer Data Classification},
  author = {Rojas, Mat{\'i}as Gabriel and Olivera, Ana Carolina and Carballido, Jessica Andrea and Vidal, Pablo Javier},
  year = {2023},
  month = feb,
  journal = {Intelligent Systems with Applications},
  volume = {17},
  pages = {200173},
  issn = {26673053},
  doi = {10.1016/j.iswa.2022.200173},
  urldate = {2023-03-15},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\W7EAEFRD\\Rojas et al. - 2023 - Memetic micro-genetic algorithms for cancer data c.pdf}
}

@article{shanSurveyModelingOptimization2010,
  title = {Survey of Modeling and Optimization Strategies to Solve High-Dimensional Design Problems with Computationally-Expensive Black-Box Functions},
  author = {Shan, Songqing and Wang, G. Gary},
  year = {2010},
  month = mar,
  journal = {Structural and Multidisciplinary Optimization},
  volume = {41},
  number = {2},
  pages = {219--241},
  issn = {1615-1488},
  doi = {10.1007/s00158-009-0420-2},
  urldate = {2023-06-04},
  abstract = {The integration of optimization methodologies with computational analyses/simulations has a profound impact on the product design. Such integration, however, faces multiple challenges. The most eminent challenges arise from high-dimensionality of problems, computationally-expensive analysis/simulation, and unknown function properties (i.e., black-box functions). The merger of these three challenges severely aggravates the difficulty and becomes a major hurdle for design optimization. This paper provides a survey on related modeling and optimization strategies that may help to solve High-dimensional, Expensive (computationally), Black-box (HEB) problems. The survey screens out 207 references including multiple historical reviews on relevant subjects from more than 1,000 papers in a variety of disciplines. This survey has been performed in three areas: strategies tackling high-dimensionality of problems, model approximation techniques, and direct optimization strategies for computationally-expensive black-box functions and promising ideas behind non-gradient optimization algorithms. Major contributions in each area are discussed and presented in an organized manner. The survey exposes that direct modeling and optimization strategies to address HEB problems are scarce and sporadic, partially due to the difficulty of the problem itself. Moreover, it is revealed that current modeling research tends to focus on sampling and modeling techniques themselves and neglect studying and taking the advantages of characteristics of the underlying expensive functions. Based on the survey results, two promising approaches are identified to solve HEB problems. Directions for future research are also discussed.},
  langid = {english},
  keywords = {Approximation,Black-box function,Computationally-expensive,Design optimization,High dimensional,Large-scale,Metamodeling,Surrogate},
  file = {C\:\\Users\\irene\\Zotero\\storage\\PQLG8UW6\\Shan y Wang - 2010 - Survey of modeling and optimization strategies to .pdf}
}

@incollection{simoesCHCBasedAlgorithmsDynamic2011,
  title = {{{CHC-Based Algorithms}} for the {{Dynamic Traveling Salesman Problem}}},
  booktitle = {Applications of {{Evolutionary Computation}}},
  author = {Sim{\~o}es, Anabela and Costa, Ernesto},
  editor = {Di Chio, Cecilia and Cagnoni, Stefano and Cotta, Carlos and Ebner, Marc and Ek{\'a}rt, Anik{\'o} and {Esparcia-Alc{\'a}zar}, Anna I. and Merelo, Juan J. and Neri, Ferrante and Preuss, Mike and Richter, Hendrik and Togelius, Julian and Yannakakis, Georgios N.},
  year = {2011},
  volume = {6624},
  pages = {354--363},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-20525-5_36},
  urldate = {2023-05-13},
  abstract = {The CHC algorithm uses an elitist selection method that, combined with an incest prevention mechanism and a method to diverge the population whenever it converges, allows the maintenance of the population diversity. This algorithm was successfully used in the past for static optimization problems. The use of memory in Evolutionary Algorithms has been proved to be advantageous when dealing with dynamic optimization problems. In this paper we investigate the use of three different explicit memory strategies included in the CHC algorithm. These strategies - direct, immigrant and associative - combined with the CHC algorithm are used to solve different instances of the dynamic Traveling Salesman Problem in cyclic, noisy and random environments. The experimental results, statistically validated, show that the memory schemes significantly improve the performance of the original CHC algorithm for all types of studied environments. Moreover, when compared with the equivalent memory-based standard EAs with the same memory schemes, the memory-based CHC algorithms obtain superior results when the environmental changes are slower.},
  isbn = {978-3-642-20524-8 978-3-642-20525-5},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\CWVGL5EC\\Simões y Costa - 2011 - CHC-Based Algorithms for the Dynamic Traveling Sal.pdf}
}

@article{smithOperatorParameterAdaptation1997,
  title = {Operator and Parameter Adaptation in Genetic Algorithms},
  author = {Smith, Jim and Fogarty, T. C.},
  year = {1997},
  month = jan,
  journal = {Soft Computing},
  volume = {1},
  number = {2},
  publisher = {{Springer (part of Springer Nature)}},
  issn = {1432-7643},
  doi = {10.1007/s005000050009},
  urldate = {2023-05-31},
  abstract = {Genetic Algorithms are a class of powerful, robust search techniques based on genetic inheritance and the Darwinian metaphor of ``Natural Selection''. These algorithms maintain a finite memory of individual points on the search landscape known as the ``population''. Members of the population are usually represented as strings written over some fixed alphabet, each of which has a scalar value attached to it reflecting its quality or ``fitness''. The search may be seen as the iterative application of a number of operators, such as selection, recombination and mutation, to the population with the aim of producing progressively fitter individuals. These operators are usually static, that is to say that their mechanisms, parameters, and probability of application are fixed at the beginning and constant throughout the run of the algorithm. However there is an increasing body of evidence that not only is there no single choice of operators which is optimal for all problems, but that in fact the optimal choice of operators for a given problem will be time-variant i.e. it will depend on such factors as the degree of convergence of the population. Based on theoretical and practical approaches, a number of authors have proposed methods of adaptively controlling one or more of the operators, usually invoking some kind of ``meta-learning'' algorithm, in order to try and improve the performance of the Genetic Algorithm as a function optimiser. In this paper we describe the background to these approaches, and suggest a framework for their classification based on the learning strategy used to control them, and what facets of the algorithm are susceptible to adaptation. We then review a number of significant pieces of work within this context, and draw some conclusions about the relative merits of various approaches and promising directions for future work.},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\N3KCIVP9\\Smith y Fogarty - 1997 - Operator and parameter adaptation in genetic algor.pdf}
}

@book{tenneComputationalIntelligenceExpensive2010,
  title = {Computational {{Intelligence}} in {{Expensive Optimization Problems}}},
  editor = {Tenne, Yoel and Goh, Chi-Keong and Hiot, Lim Meng and Ong, Yew Soon},
  year = {2010},
  series = {Adaptation {{Learning}} and {{Optimization}}},
  volume = {2},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-10701-6},
  urldate = {2023-06-04},
  isbn = {978-3-642-10700-9 978-3-642-10701-6},
  keywords = {algorithm,algorithms,computational intelligence,control,data mining,evolution,evolutionary algorithm,fuzzy,intelligence,model,modeling,neural network,neural networks,optimization,simulation},
  file = {C\:\\Users\\irene\\Zotero\\storage\\9FRJAPUP\\Tenne y Goh - 2010 - Computational Intelligence in Expensive Optimizati.pdf}
}

@article{tuRobustStochasticGenetic2004,
  title = {A {{Robust Stochastic Genetic Algorithm}} ({{StGA}}) for {{Global Numerical Optimization}}},
  author = {Tu, Z. and Lu, Y.},
  year = {2004},
  month = oct,
  journal = {IEEE Transactions on Evolutionary Computation},
  volume = {8},
  number = {5},
  pages = {456--470},
  issn = {1089-778X},
  doi = {10.1109/TEVC.2004.831258},
  urldate = {2023-05-31},
  abstract = {Many real-life problems can be formulated as numerical optimization of certain objective functions. However, often an objective function possesses numerous local optima, which could trap an algorithm from moving toward the desired global solution. Evolutionary algorithms (EAs) have emerged to enable global optimization; however, at the present stage, EAs are basically limited to solving small-scale problems due to the constraint of computational efficiency. To improve the search efficiency, this paper presents a stochastic genetic algorithm (StGA). A novel stochastic coding strategy is employed so that the search space is dynamically divided into regions using a stochastic method and explored region-by-region. In each region, a number of children are produced through random sampling, and the best child is chosen to represent the region. The variance values are decreased if at least one of five generated children results in improved fitness, otherwise, the variance values are increased. Experiments on 20 test functions of diverse complexities show that the StGA is able to find the near-optimal solution in all cases. Compared with several other algorithms, StGA achieves not only an improved accuracy, but also a considerable reduction of the computational effort. On average, the computational cost required by StGA is about one order less than the other algorithms. The StGA is also shown to be able to solve large-scale problems.},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\ZN4WS3BR\\Tu y Lu - 2004 - A Robust Stochastic Genetic Algorithm (StGA) for G.pdf}
}

@article{universityofduhokBESTPRACTICESRECOMMENDATIONS2019,
  title = {{{BEST PRACTICES AND RECOMMENDATIONS FOR WRITING GOOD SOFTWARE}}},
  author = {{University of Duhok} and Sarhan, Qusay},
  year = {2019},
  month = nov,
  journal = {The Journal of the University of Duhok},
  volume = {22},
  number = {1},
  pages = {90--105},
  issn = {18127568, 25214861},
  doi = {10.26682/sjuod.2019.22.1.11},
  urldate = {2023-06-04},
  abstract = {Writing good software is not an easy task, it requires a lot of coding experience and skills. Therefore, inexperienced software developers or newbies suffer from this critical task. In this paper, we provide guidelines to help in this important context. It presents the most important best practices and recommendations of writing good software from software engineering perspective regardless of the software domain (whether for desktop, mobile, web, or embedded), software size, and software complexity. The best practices provided in this paper are organized in taxonomy of many categories to ease the process of considering them while developing software. Furthermore, many useful, practical, and actionable recommendations are given mostly in each category to be considered by software developers.},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\WK2UXZLG\\University of Duhok y Sarhan - 2019 - BEST PRACTICES AND RECOMMENDATIONS FOR WRITING GOO.pdf}
}

@article{vargasEstrategiasParaMejorar,
  title = {{Estrategias para mejorar el Balance entre Exploraci\'on y Explotaci\'on en Optimizaci\'on de Enjambre de Part\'iculas}},
  author = {Vargas, Lic Yenny Noa},
  langid = {spanish},
  note = {Mirar referencias, principalmente para introduccion},
  file = {C\:\\Users\\irene\\Zotero\\storage\\3J2C2GWK\\Vargas - Estrategias para mejorar el Balance entre Explorac.pdf}
}

@article{wangHybridMetaheuristicAlgorithm2021,
  title = {Hybrid Metaheuristic Algorithm Using Butterfly and Flower Pollination Base on Mutualism Mechanism for Global Optimization Problems},
  author = {Wang, Zhongmin and Luo, Qifang and Zhou, Yongquan},
  year = {2021},
  month = oct,
  journal = {Engineering with Computers},
  volume = {37},
  number = {4},
  pages = {3665--3698},
  issn = {0177-0667, 1435-5663},
  doi = {10.1007/s00366-020-01025-8},
  urldate = {2023-02-18},
  abstract = {The butterfly optimization algorithm (BOA) is a new metaheuristic algorithm that is inspired from food foraging behavior of the butterflies. Because of its simplicity and effectiveness, the algorithm has been proved to be effective in solving global optimization problems and applied to practical problems. However, BOA is prone to local optimality and may lose its diversity, thus suffering losses of premature convergence. In this work, a hybrid metaheuristic algorithm using butterfly and flower pollination base on mutualism mechanism called MBFPA was proposed. Firstly, the flower pollination algorithm has good exploration ability and the hybrid butterfly optimization algorithm and the flower pollination algorithms greatly improve the exploration ability of the algorithm; secondly, the symbiosis organisms search has a strong exploitation capability in the mutualism phase. By introducing the mutualism phase, the algorithm's exploitation capability is effectively increased and the algorithm's convergence speed is accelerated. Finally, the adaptive switching probability is increased to increase the algorithm's balance in exploration and exploitation capabilities. In order to evaluate the effectiveness of the algorithm, in the 49 standard test functions, the proposed algorithm was compared with six basic metaheuristic algorithms and five hybrid metaheuristic algorithms. MBFPA has also been used to solve five classic engineering problems (three-bar truss design problem; multi-plate disc clutch brake design; welded beam design; pressure vessel design problem; and speed reducer design). The results show that the proposed method is feasible and has good application prospect and competitiveness.},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\IENPY2WT\\Wang et al. - 2021 - Hybrid metaheuristic algorithm using butterfly and.pdf}
}

@article{witzgallMathematicalMethodsSite1975,
  title = {Mathematical Methods of Site Selection for {{Electronic Message Systems}} ({{EMS}})},
  author = {Witzgall, C.},
  year = {1975},
  month = jun,
  journal = {NASA STI/Recon Technical Report N},
  volume = {76},
  pages = {18321},
  urldate = {2023-06-02},
  abstract = {The concept of electronic message (mail) transmission was the subject of several feasibility studies during the past decade. It requires the installation of electronic message handling facilities at selected locations. If transmission is to be via communications satellite, then any such facility can transmit to and receive from any other one. In the report, the mathematical aspects of choosing the number and locations of these facilities are examined. An inventory of solution methods is presented, along with recommendations as to which among them should be employed or developed further.},
  keywords = {Communications and Radar,Cost Analysis,Linear Programming,Messages,Network Synthesis,Radio Relay Systems,Systems Engineering,Telecommunication},
  annotation = {ADS Bibcode: 1975STIN...7618321W}
}

@techreport{witzgallMathematicalMethodsSite1975a,
  title = {Mathematical Methods of Site Selection for Electronic Message Systems ({{EMS}})},
  author = {Witzgall, Christoph},
  year = {1975},
  edition = {Zeroth},
  number = {NBS IR 75-737},
  pages = {NBS IR 75-737},
  address = {{Gaithersburg, MD}},
  institution = {{National Bureau of Standards}},
  doi = {10.6028/NBS.IR.75-737},
  urldate = {2023-06-04},
  abstract = {The concept of electronic message (mail) transmission was the subject of several feasibility studies during the past decade. It requires the installation of electronic message handling facilities at selected locations. If transmission is to be via communications satellite, then any such facility can transmit to and receive from any other one. In the report, the mathematical aspects of choosing the number and locations of these facilities are examined. An inventory of solution methods is presented, along with recommendations as to which among them should be employed or developed further.},
  langid = {english},
  file = {C\:\\Users\\irene\\Zotero\\storage\\3VDSLKLL\\Witzgall - 1975 - Mathematical methods of site selection for electro.pdf}
}

@misc{wongEvolutionaryMultimodalOptimization2015,
  title = {Evolutionary {{Multimodal Optimization}}: {{A Short Survey}}},
  shorttitle = {Evolutionary {{Multimodal Optimization}}},
  author = {Wong, Ka-Chun},
  year = {2015},
  month = aug,
  number = {arXiv:1508.00457},
  eprint = {1508.00457},
  primaryclass = {cs, q-bio},
  publisher = {{arXiv}},
  urldate = {2023-03-12},
  abstract = {Real world problems always have different multiple solutions. For instance, optical engineers need to tune the recording parameters to get as many optimal solutions as possible for multiple trials in the varied-line-spacing holographic grating design problem. Unfortunately, most traditional optimization techniques focus on solving for a single optimal solution. They need to be applied several times; yet all solutions are not guaranteed to be found. Thus the multimodal optimization problem was proposed. In that problem, we are interested in not only a single optimal point, but also the others. With strong parallel search capability, evolutionary algorithms are shown to be particularly effective in solving this type of problem. In particular, the evolutionary algorithms for multimodal optimization usually not only locate multiple optima in a single run, but also preserve their population diversity throughout a run, resulting in their global optimization ability on multimodal functions. In addition, the techniques for multimodal optimization are borrowed as diversity maintenance techniques to other problems. In this chapter, we describe and review the state-of-the-arts evolutionary algorithms for multimodal optimization in terms of methodology, benchmarking, and application.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Quantitative Methods},
  file = {C\:\\Users\\irene\\Zotero\\storage\\46MBKNGY\\Wong - 2015 - Evolutionary Multimodal Optimization A Short Surv.pdf;C\:\\Users\\irene\\Zotero\\storage\\GLGC39XH\\1508.html}
}
