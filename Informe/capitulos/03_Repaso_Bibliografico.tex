\chapter{Repaso Bibliográfico}

En esta sección se lleva a cabo una revisión bibliográfica sobre el tema en el que hemos centrado el proyecto. 
Buscamos con ello, llevar a cabo un pequeño recordatorio para poder entender los distintos ámbitos que más se han tratado y centrado los estudios en cuanto al diseño de metaheurísticas, las cuales se usan para resolver problemas cada vez más complejos.  
Posteriormente utilizaremos estos conocimientos para nuestro propio diseño de una metaheurística útil para problemas combinatorios \textit{expensive}.

% Cada frase se desarrolla en un párrafo, con una o varias referencias

\section{Contexto Bibliográfico}

% Párrafo sobre las metaheurísticas, con referencias [evocomp, EABook]

La computación evolutiva (\textit{evolutionary computation}, EC) es un área de la ciencia de la computación que usa ideas de la evolución biológica para resolver problemas computacionales. 
La evolución es, en efecto, un método de búsqueda entre un número enorme de posibilidades de ``soluciones'' que permitan a los organismos sobrevivir y reproducirse en sus ambientes. 
También se puede ver la evolución como un método de adaptación a un entorno cambiante. 
En \parencite{backEvolutionaryComputationOverview1996} nos podemos encontrar con un resumen del desarrollo de la computación evolutiva en el tiempo junto con aplicaciones reales de algoritmos evolutivos (tanto comerciales como científicas), como podría ser el uso de programación genética para mejorar estrategias óptimas de recolección. 
Si consideramos la computación evolutiva como un medio para encontrar buenas soluciones (aunque no sean las óptimas) dado un problema de optimización, es natural considerar que su hibridación con métodos de optimización existentes resultará en mejorar su rendimiento al explotar sus ventajas. 
Tales métodos de optimización se refieren desde algoritmos exactos estudiados en programación matemática \parencite{islamMATHEMATICALPROGRAMMING2020} hasta algoritmos heurísticos hechos a medida para unos problemas dados. 
Los llamados algoritmos metaheurísticos también tienen un objetivo similar, y pueden ser combinados con EC, incluso si ambos enfoques suelen competir entre si. 
En el libro \parencite{michalewiczHandbookEvolutionaryComputation1997} se presentan varias posibilidades de combinar ECs con métodos de optimización, poniendo énfasis en la optimización de problemas combinatorios, tales como métodos \textit{greedy}, construcciones heurísticas de soluciones factibles, programación dinámica, etc. 


% Introducir los AGs con su referencia. Dentro del AG indicar los operadores comunes con su referencia (Nam)

Una de las versiones de algoritmos evolutivos más utilizadas son los algoritmos genéticos (AG), que será en el que nos centremos ya que supondrá ser un algoritmo base para el desarrollo de este proyecto. 
Los algoritmos genéticos son algoritmos basados en poblaciones que se pueden describir como la combinación de dos procesos: la generación de elementos del espacio de búsqueda (recombinación o mutación de la población) y la actualización (selección y redimensionamiento) para producir nuevas soluciones basadas en el conjunto de puntos que se crean junto con los de la anterior población \parencite{smithOperatorParameterAdaptation1997} \parencite{tuRobustStochasticGenetic2004}. 
En \parencite{backEvolutionaryComputationOverview1996} se presenta una lista de componentes para la versión más simple de un AG, que se puede resumir en:
\begin{itemize}
	\item Una población de soluciones candidatas a un problema dado, cada una codificada de acuerdo a un esquema de representación elegido. 
	\item Una función \textit{fitness} que asigna un valor numérico a cada cromosoma (solución) de una población para medir su calidad como candidato a solución del problema.
	\item Un conjunto de operadores que se aplicarán a los cromosomas para crear una nueva población. 
Estos suelen incluir:
	\begin{itemize}
		\item Operador de Cruce: Dos cromosomas padres recombinan sus genes para producir una o más soluciones hijas. 
		\item Mutación: Uno o varios genes de una solución se modifican de forma aleatoria. 
	\end{itemize}
\end{itemize}
Una explicación más completa y detallada de lo relativo a AGs se puede encontrar en \parencite{reevesGeneticAlgorithms2010}. 
En dicho capítulo también presentan algunos artículos y libros donde encontrar aplicaciones de AGs exitosas para la optimización de problemas combinatorios, entre ellas se destaca \parencite{reevesFeatureArticleGenetic1997}, la cual lista algunas de las referencias más útiles y accesibles que podrían ser de interés para gente experimentando con metaheurísticas, como podrían ser el problema del viajante de comercio, problemas relacionados con grafos, problema de la mochila en forma binaria, etc. 

% Introducir el CHC con su referencia, y algún artículo de aplicación.

Cualquier algoritmo que siga un ciclo reproducción-recombinación en una población de estructuras se puede denominar un AG en el sentido más amplio del término. 
Sin embargo, desde el trabajo de Holland (1975) 
%\ref{johnhhollandAdaptationNaturalArtificial1975}
para clasificar cualquier algoritmo como un AG en un sentido más estricto, se debía demostrar que su comportamiento de búsqueda reflejaba lo que Holland llamaba un ``paralelismo implícito''. 
Eshelman \parencite{eshelmanCHCAdaptiveSearch1991a} comprueba que CHC, un algoritmo genético no tradicional, ciertamente muestra paralelismo implícito. 
Incluso justifica que algunas de las características que parecerían descalificarlo como un verdadero GA no solo no lo descalifican, sino que lo hacen más potente que un AG tradicional.  
Eshelman describe en detalle los componentes (prevención de incesto, cruce HUX, reinicios de población...) y las características de CHC, lo contrasta con un AG tradicional, aporta una justificación teórica de sus diferencias y provee algunas comparaciones empíricas. 
Un ejemplo donde se aplique el algoritmo CHC para resolver un problema lo podemos encontrar en el artículo \parencite{simoesCHCBasedAlgorithmsDynamic2011}, donde se estudia el uso de tres estrategias de memoria explícita combinadas con el algoritmo CHC para resolver distintas instancias del problema del viajante de comercio dinámico. 

% Párrafo sobre problemas expensives, incluyendo referencia de repaso bibliográfico que te envié

Llamaremos \textbf{problemas de optimización costosos o \textit{expensive}} (EOP) a aquellos problemas que requieran costes elevados o incluso inalcanzables para evaluar candidatos a soluciones. 
Existen una gran cantidad de EOPs relativos a aplicaciones en el mundo real; además, con el progreso de la sociedad y problemas emergentes como las \textit{smart cities}, la era del \textit{big data}, etc., la resolución más eficiente de EOPs se ha vuelto cada vez más esencial para prosperar en distintos campos. 
Sin embargo, debido al coste tan elevado de cálculo, es complicado para los algoritmos de optimización encontrar una solución satisfactoria a dichos EOPs. 
Por ello, la EC se ha adoptado en gran medida para resolver EOPs, llevando a un campo de investigación de rápido crecimiento. 
Hasta la fecha, se han conducido varias investigaciones sobre el uso de EC para EOP y han alcanzado un éxito considerable \parencite{liEvolutionaryComputationExpensive2022} \parencite{jinComprehensiveSurveyFitness2005} \parencite{shanSurveyModelingOptimization2010} \parencite{tenneComputationalIntelligenceExpensive2010}.
El concepto de EOP se suele mencionar junto con algunos conceptos del problema similares, como podría ser un problema de optimización a gran escala. 
En \parencite{liEvolutionaryComputationExpensive2022} se hacen referencia y se explican varios de estos conceptos. 

% Indicar que hay problemas combinatorios que no están cubiertos, citar trabajo de neuroevolución, y concreto mío, que hace muy pocas evaluaciones y aún así tarda demasiado tiempo

Sin embargo, si bien somos capaces de encontrar una gran cantidad de investigaciones para EOPs, debemos notar que la vasta mayoría se refieren a problemas con parámetros reales, es decir, que pertenecen a los casos continuos. 
Esto implica que para el ámbito de los problemas combinatorios \textit{expensive} nos encontramos con una sequía de estudios al respecto y, por tanto, algoritmos desarrollados para optimizar su resolución. 
Un ejemplo de este tipo de problemas lo podemos encontrar en el artículo \parencite{martinezLightsShadowsEvolutionary2021b}, donde se emplea una fusión de algoritmos de optimización basados en la biología y modelos de \textit{Deep Learning}. 
Para recalcar la necesidad de algoritmos pensados para problemas combinatorios \textit{expensive} podemos mencionar el artículo \parencite{poyatosEvoPruneDeepTLEvolutionaryPruning2023a}, donde se propone el uso de EvoPruneDeepTL (un modelo de poda evolutiva para aprendizaje por transferencia basado en redes neuronales profundas) aplicado a un problema de clasificación de imágenes. 
En dicho artículo los propios autores reconocen que estuvieron obligados a reducir en gran medida el número de evaluaciones de los algoritmos utilizados, lo que impedía el uso de tests estadísticos para estudiar el nivel de significación de las diferencias encontradas, debido a los elevados tiempos de ejecución para cada simulación. 

%Describir posibles opciones a considerar
%  - Uso de parámetros adaptativos y auto-adaptativos [referencia], guiándose no solo por mejor actual, si no por histórico.
Los AG son algoritmos de búsqueda potentes que pueden ser aplicados a un amplio rango de problemas. 
Generalmente, el establecimiento de los parámetros se realiza antes de ejecutar un AG y esta configuración se mantiene constante durante toda la ejecución. 
Sin embargo, es interesante considerar el uso parámetros auto-adaptativos. 
Es decir, tomar un enfoque en el que el control de los parámetros de un AG pueda ser codificado dentro de los cromosomas de cada individuo. 
Así, los valores son totalmente dependientes del mecanismo de evolución y del contexto del problema. 
Pellerin et al. \parencite{pellerinSelfadaptiveParametersGenetic2004} realizan  un estudio sobre este tipo de comportamiento y obtienen resultados que indican un enfoque prometedor de desarrollo de AGs con parámetros auto-adaptativos que no requieran que el usuario los pre-ajuste. 
Podemos también encontrar una breve clasificación de los distintos métodos de auto-adaptabilidad propuestos en la literatura: empírico y adaptativo \parencite{eibenParameterControlEvolutionary1999} \parencite{loboOverviewParameterlessGenetic2008}: 
\begin{itemize}
	\item Enfoque empírico: Se basan solo en la experimentación y en la observación. 
	Miden el rendimiento de las AG por ensayo y error, a la vez que se modifican los parámetros del algoritmo \parencite{eibenParameterControlEvolutionary1999}. 
	Por lo tanto, es necesario encontrar buenos valores para dichos parámetros antes de ejecutar el algoritmo, y estos valores se mantendrán constantes durante la ejecución. 
	\item Enfoque adaptativo. 
	Nos encontramos con dos categorías:
	\begin{itemize}
		\item Parámetros adaptativos limitados: Analiza los efectos aislados de uno o dos parámetros teniendo en cuenta el resto \parencite{lisParallelGeneticAlgorithm1996}. 
		\item Parámetros auto-adaptativos: Refiriéndose a las técnicas que permite la evolución o adaptación de diversos parámetros de AG durante su ejecución \parencite{grefenstetteOptimizationControlParameters1986} \parencite{phamCompetitiveEvolutionNatural1994}.
	\end{itemize}
\end{itemize}

%  - Modificación del operador de cruce [referencia]
Como ya se ha indicado, los AGs tienen gran capacidad de adaptarse a la estructura del espacio de soluciones y controlar el equilibrio entre búsquedas locales y globales, incluso sin ajustar sus parámetros, como serían la probabilidad de cruce o mutación. 
Obviamente, ningún algoritmo es perfectamente adecuado para todos los problemas de acuerdo al teorema \textit{No free lunch} \parencite{wolpertNoFreeLunch1997}, pero un determinado tipo de cruce puede llegar a resolver un gran número de problemas. 
Por ello, se han propuesto una gran cantidad de variantes de AGs en las que se modifican el tipo de cruce a lo largo de estos últimos años. 
Chaturvedi y Sharma en el capítulo \textit{A Modified Genetic Algorithm Based on Improved Crossover Array Approach} \parencite{chaturvediModifiedGeneticAlgorithm2019} estudiaron la introducción de un AG con un operador de cruce mejorado de tal forma que se eligiese dinámicamente el tipo de operador de cruce que se iba a utilizar en el problema. 
Cheng y Gen \parencite{chengCrossoverIntensiveSearch1994} propusieron un nuevo operador de cruce para el problema del viajante de comercio con el objetivo de mejorar el AG tanto en tiempo como en precisión mediante el uso de relaciones de precedencia local entre los genes para obtener candidatos de posibles \textit{edges} y relaciones de precedencia global entre los genes para obtener al mejor entre los candidatos. 
Quiobing y Lixin \parencite{qiongbingNewCrossoverMechanism2016} propusieron un nuevo mecanismo de cruce para AG con cromosomas de longitud variable para problemas de optimización de caminos. 


% - Elección de padres
Los métodos de selección de padres son básicos dentro de los AGs, ya que determinan las posibilidades de los individuos de influir en las generaciones siguientes. 
Dado que en los AGs el operador que produce diversidad es el cruce, es necesaria una adecuada selección de los individuos para poder conseguir un adecuado equilibrio entre exploración y explotación. 
En este trabajo se utilizarán dos métodos:
\begin{itemize}
	\item Una Selección por Torneo clásica, donde se eligen de forma aleatoria cierta cantidad de individuos de la población y solo elegimos el mejor. 
	\item Emparejamiento Variado inverso (\textit{Negative Assortative Mating}, NAM) \parencite{fernandesStudyNonrandomMating2001}. 
	Está orientado a generar diversidad, eligiéndose un elemento de forma aleatoria y otro grupo de individuos; de este grupo elegiremos como segundo padre a aquel elemento más diferente del primero. 
\end{itemize}

%   - Otros?
En los AG estacionarios se debe determinar los individuos que serán reemplazados por los nuevos individuos generados. 
Esta elección puede determinar el nivel de presión selectiva que se exige a los individuos para ser introducidos o permanecer en la población, y la pérdida de diversidad que se introduce conforme el proceso de búsqueda avanza. 
Se han propuesto numerosas estrategias de reemplazo, algunas como introducir alta presión selectiva, como sería el reemplazar el peor elemento de la población \parencite{goldbergComparativeAnalysisSelection1991}, otras para mantener una alta diversidad, como serían los métodos de multitud o \textit{crowding} \parencite{mahfoudCrowdingPreselectionRevisited1992} que buscan que las nuevas soluciones reemplacen las soluciones parecidas a ellas, o un equilibrio entre ambas. 

% Referencias sobre el problema, ya tenías alguna, busca más y sobre su interés.

El problema de la mochila cuadrático (QKP, \textit{quadratic knapsack problem}) binario fue introducido por Gallo et al. \parencite{galloQuadraticKnapsackProblems1980} y resulta una generalización del clásico problema de la mochila (KP, \textit{knapsack problem}), donde el beneficio que aporta cada elemento deja de ser solo individual, pudiendo aportar más valor si se combina con otro elemento. 
Aunque el QKP no se ha estudiado de forma tan intensiva como el problema de la asignación cuadrática, nos podemos encontrar con numerosos artículos a lo largo de estos últimos años relativos a este problema. 
Como cabría esperar debido a su generalidad, el QKP tiene un rango de aplicaciones muy amplio. 
Witzgall \parencite{witzgallMathematicalMethodsSite1975} presentó un problema que surge en telecomunicaciones cuando se debe seleccionar un número de localizaciones para las estaciones de satélites de forma que el tráfico global entre estas estaciones se maximice y la restricción de presupuesto se respete. 
Este problema resulta ser un QKP. 
Nos encontramos con modelos similares al considerar la localización de aeropuertos, estaciones de tren o terminales de manejo de carga \parencite{rhysSelectionProblemShared1970}. 
Ferreira et al. \parencite{ferreiraFormulationsValidInequalities1996} consideran un problema de diseño VLSI (\textit{Very Large Scale Integration}) donde los grafos de gran tamaño necesitan ser descompuestos en grafos de más pequeños de tamaño manejable. 
El problema de optimización asociado para un único subgrafo puede ser reconocido como un QKP de minimización. 
Pisinger \parencite{pisingerQuadraticKnapsackProblem2007} realizó un estudio sobre los límites superiores presentados en la literatura y muestra la estanqueidad relativa de los diversos límites, proporcionando resultados y un estudio experimental donde se comparan estos resutalos con respecto a la potencia y el esfuerzo computacional. 


%  - Describir que usarás la guía de buenas prácticas [referencia]

Por último, se debe mencionar que se ha intentado seguir una guía de buenas prácticas (artículo \parencite{latorrePrescriptionMethodologicalGuidelines2021}), aunque hay un punto que no se ha podido cumplir: el uso de benchmarks, debido a la ausencia de algoritmos diseñados específicamente para resolver este tipo de problemas. 
Podemos resumir lo utilizado de dicha guía en: 
\begin{itemize}
	\item \textbf{Validación de los resultados}: 
	En tanto que no existen benchmarks que podamos utilizar para este trabajo, no podemos comparar nuestros resultados con otros algoritmos. 
	Sin embargo, se realizarán tests estadísticos no paramétricos (\parencite{derracPracticalTutorialUse2011}) entre las diferentes versiones del algoritmo que vamos a desarrollar para poder asegurar que realmente se están produciendo mejoras. 
	
	\item \textbf{Análisis de los componentes y ajuste de parámetros de la propuesta}: 
	Este análisis y justificación se realizará a lo largo de este trabajo.
	
	\item \textbf{Utilidad del algoritmo propuesto}: 
	Como ya se ha indicado anteriormente y se volverá a indicar más tarde, no hay algoritmos que estén orientados a resolver problemas de optimización combinatorios \textit{expensive}, por lo que este proyecto no es solo útil, sino que también supone una novedad.
	
\end{itemize}