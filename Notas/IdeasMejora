CHC:
  - Selección Elitista: Selecciona los N mejores cromosomas entre padres e hijos. Los N mejores elementos encontrados hasta el momento permanecerán en la población actual.
  - Cruce Uniforme (HUX): Intercambia exactamente la mitad de los alelos que son distintos en los padres. Garantiza que los hijos tengan una distancia Hamming máxima a sus dos padres. -> Hecho
  - Prevención de Incesto: Se forman N/2 parejas con los elementos de la población. Solo se cruzan las parejas cuyos miembros difieren en un número determinado de bits.
 El umbral se inicializa a H=L/4 (L es la longitud del cromosoma). Si durante un ciclo no se crean descendientes mejores que los de la población anterior, al umbral de cruce se le resta 1.
  - Reinicialización: Cuando el umbral de cruce es menor que cero, la población se reinicia:
    a) Usando el mejor elemento como plantilla (35% de variación aleatoria) e incluyendo una copia suya
    b) Manteniendo el mejor o parte de los mejores de la población y el resto se generan aleatoriamente

Podríamos aumentar el número de parejas (en vez de 1, que sean 2) siguiendo la indicación de Prevención de Incesto, aunque esto podría suponer algunas pérdidas en ejecuciones. 
Podríamos aplicar la Reinicialización b) cuando reiniciamos los elementos a tener en cuenta.


Para aumentar la diversidad podríamos fomentar el uso de elementos que no se encuentren entre los más usado por los mejores ni peores de forma greedy. Pero entonces no nos podríamos olvidar de los mejores y los peores que tenemos entre etapas. Se podría considerar que solo intentaremos interactuar con dichos elementos de la forma normal (greedy). Se intentarían eliminar los peores y, en vez de introducir los mejores, introducimos los meh. 

Se podría utilizar GRASP en vez de Greedy. Es decir, en vez de elegir el elemento con mayor valor/peso, se genera una lista con los x mejores elementos y se elige uno aleatorio de ahí.

Se podría seguir la idea del algoritmo del enfriamiento del metal y en las últimas 50 iteraciones, en vez de seguir la forma de un genético, se podría realizar alguna especie de búsqueda local sobre la mejor solucion.

Si en cierto número de iteraciones no se logra introducir ningún hijo en la población, podríamos reiniciar la población, manteniendo los mejores, con el fin de evitar estancamientos. El problema de reiniciarlo de esta forma, es que puede darse el caso en que se tenga que reiniciar muchas veces y perdamos el tiempo.

Se podría considerar que en vez de utilizar soluciones aleatorias, se usase soluciones obtenidas por GRASP.


12/03/23 (Latest)
En el operador de reparación cambiar la adición/eliminación Greedy por GRASP. Así eliminamos que siempre se elijan los mismos elementos, aumentando la exploración, pero manteniendo el ser competente.
Esto está propuesto en (Genetic and Memetic Algorithm with Diversity Equilibrium based on Greedy Diversification, pg 6).
A esto se le llama operador de diversificación

Se podría generar 1 o 2 soluciones aleatorias por iteración para hacerlas competir con el resto. En [The Shifting Balance Genetic Algorithm: Improving the GA in a Dynamic Environment] se divide la población en un core y unas colonias, y a medida que pasa el tiempo las colonias migran hacia el core y una subpoblación del core migra hacia las colonias para representar las distintas condiciones el entorno. 
En tanto que nuestro tamaño de población es bastante pequeño, en vez de separar la población, podríamos generar una par de soluciones nuevas para simularlo.

GRASP:
int GRASP(int sol[], double &peso, bool minimizar){
  vector<int> indices;
  vector<int> valores;
  double sigma = 0.1;
  
  if(minimizar){ //Encontrar peores elementos
    for(int i = 0; i < getSize(); ++i){
      if(sol[i] == 1){
        indices.push_back(i);
        valores.push_back(_ag.calcularRelValor(i,sol));
      }
    }
    //Ordenamos los elementos de peor a mejor
    vector<int> aux(indices.size());
    iota(aux.begin(), aux.end(), 0);
    sort(aux.begin(), aux.end(),
      [&] (int A, int B) -> bool{
        return valores[A] < valores[B];
      }
    );
    //Nos quedamos con los elementos cuyo valor relativo <= (1+sigma)*valor_peor
    bool found = false;
    for(int i = 1; i < aux.size() && !found; ++i){
      if(valores[aux[i]] > (1+sigma)*valores[aux[0]]){
        found = true;
        aux.erase(aux.begin()+i,aux.end());
      }
    }
  }
  else{ //Encontrar mejores elementos a añadir
    for(int i = 0; i < getSize(); ++i){
      if(sol[i] == 0){
        if(checkAdd(i, peso, sol)){
          indices.push_back(i);
          valores.push_back(_ag.valueIfAdded(i,sol);
        }
      }
    }
    //Ordenamos los elementos de mejor a peor
    vector<int> aux(indices.size());
    iota(aux.begin(), aux.end(), 0);
    sort(aux.begin(), aux.end(),
      [&] (int A, int B) -> bool{
        return valores[A] > valores[B];
      }
    );
    //Nos quedamos con los elementos cuyo valor añadido >= (1-sigma)*valor_mejor
    bool found = false;
    for(int i = 1; i < aux.size() && !found; ++i){
      if(valores[aux[i]] < (1-sigma)*valores[aux[0]]){
        found = true;
        aux.erase(aux.begin()+i,aux.end());
      }
    }
  }
  
  //Elegimos aleatoriamente uno de los elementos considerados
  Random::shuffle(aux);
  return indices[aux[0]};
}

En [Genetic and Memetic Algorithm with Diversity Equilibrium based on Greedy Diversification, pg 8] se propone usar el GRASP en vez del operador de mutación -> Se podría decir que es elimine alguno de los peores elementos y se añada alguno de los mejores.

Pedir archivo [Micro-genetic algorithms for stationary and non-stationary function optimization], In: Advances in Intelligent Robotics Systems Conference, International Society for Optics and Photonics (1990), pp. 289–296

http://sepwww.stanford.edu/public/docs/sep112/gabriel1/paper_html/node11.html
Cuando tratamos con un problemas con alta dimensionalidad, puede ser difícil o costoso en términos de tiempo para todos los parámetros del modelo converger dentro de un margen de error dado. En particular, cuando el número de parámetros del modelo aumenta, también lo hace el tamaño de población requerida.
Un tamaño de población grande implica grandes números de evaluación-coste.
Una alternativa es el uso de micro algoritmos genéticos, que evolucionan poblaciones muy pequeñas queson muy eficientes localizando áreas prometedoras del espacio de búsqueda. Obviamente, las poblaciones pequeñas son incapaces de mantener la diversidad por muchas generaciones, pero la población puede ser reiniciada cada vez que la población se pierde, manteniendo solo la mejor solución obtenida.
Reiniciar la población muchas veces durante la ejecución del algoritmo genético tiene el beneficio añadido de evitar la convergencia prematura debido a la presencia de un individuo con un buen valor, lo que posee el riesgo de prevenir más exploraciones del espacio de búsqueda y haga converger al programa a un mínimo local.
Además, en tanto que no estamos tratando con poblaciones largos, la convergencia puede ser alcanzada más rápidamente y con menos requisitos de memoria para almacenar la población

Se podría utilizar la diversidad de la población usando la fórmula de [The Shifting Balance Genetic Algorithm: Improving the GA in a Dynamic Environment] para comprobar cuándo la población ha convergido y reiniciarla o aumentar la mutación o algún otro cambio. Posible implementación:

void vectorToInt(vector<int> sol, int[] solb){
  for(int i = 0; i < getSize(); ++i){
    solb[i] = 0;
  }
  for(int i = 0; i < sol.size(); ++i){
    solb[sol[i]] = 1;
  }
}

double diversity(vector<vector<int>> pob){
  int auxSol1[getSize()];
  int auxSol2[getSize()];
  double d = 1/(getSize()*pob.size()*(pob.size()-1));
  double aux=0;
  for(int i = 0; i < getSize()-1; ++i){
    vectorToInt(pob[i],auxSol1);
    for(int j = i; j < getSize(); ++j){
      vectorToInt(pob[i],auxSol2);
      aux += chc.distanciaHamming(auxSol1,auxSol2);
    }
  }
  aux = aux*2;
  return d*aux;
}

15/03/23
Modificar el operador de cruce de tal forma que se calcule cuál es la mejor solución entre los padres y de esta solución se tome el 60/70/80% de los cromosomas (a estudiar) y se les asigne a ambos hijos -> Tener dos vectores con los indices y desordenar ambos, asignando los x% primeros cromosomas de cada vector de índices del mejor padre.
Otra opción, por ver, sería usar la diferencia entre el fitness de los padres

Se ha dado el visto bueno para probar a sustituir el Greedy normal del operador de Reparación del AG por un GRASP con el fin de aumentar la diversidad.

Si hay margen suficiente para que converjan las soluciones de la población, se podría intentar el reiniciar la población (excepto la mejor)

19/03/23
Se ha probado el cruce de cromosomas no exclusivo con porcentajes 50/60/70/80 -> Resulta que a mayor porcentaje peores son las soluciones finales, por lo que el 50% es mejor
Se procede a añadir una función para calcular la diversidad que hay en la población, para comprobar si lo anterior se debe a que al obtener nuevas soluciones altamente parecidas a sus padres la población se queda estancada.
Tras calcular la diversidad (diversityCruceGACEP) y pasarlo por TacoLab se ha obtenido que, efectivamente, a mayor porcentaje de cruce, más reduce la diversidad.
Por lo tanto, se añadirán los resultados del cruce no exclusivo del 50% en archivo de general.
Tras pasar el archivo general por TacoLab, se obtiene que el cruce no exclusivo es un segundo muy cercano al GACEPTotal, incluso lo mejora hasta el 30% de las ejecuciones.

Lo siguiente que se probará será introducir GRASP al operador de cruce.
